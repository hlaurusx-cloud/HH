import streamlit as st
import pandas as pd
import numpy as np
import os
import joblib
import plotly.express as px
import plotly.graph_objects as go
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor
from sklearn.metrics import (
    accuracy_score, auc, roc_curve, confusion_matrix,
    mean_absolute_error, mean_squared_error, r2_score
)
import warnings
warnings.filterwarnings("ignore")

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="í•˜ì´ë¸Œë¦¬ë“œëª¨í˜• í”„ë ˆì„ì›Œí¬", layout="wide")

# ----------------------
# 1. í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
# ----------------------
st.set_page_config(
    page_title="í•˜ì´ë¸Œë¦¬ë“œëª¨í˜• ë™ì  í”„ë ˆì„ì›Œí¬ï¼ˆì˜ì‚¬ê²°ì •ë‚˜ë¬´+íšŒê·€ë¶„ì„ï¼‰",
    page_icon="ğŸ“Š",
    layout="wide"
)

# ì „ì—­ ìƒíƒœ ê´€ë¦¬ï¼ˆê° ë‹¨ê³„ ë°ì´í„°/ëª¨ë¸ ì €ì¥ï¼Œìƒˆë¡œê³ ì¹¨ ì‹œ ì†ì‹¤ ë°©ì§€ï¼‰
if "step" not in st.session_state:
    st.session_state.step = 0  # 0:ì´ˆê¸°í™”ë©´ 1:ë°ì´í„°ì—…ë¡œë“œ 2:ë°ì´í„°ì‹œê°í™” 3:ë°ì´í„°ì „ì²˜ë¦¬ 4:ëª¨ë¸í•™ìŠµ 5:ì˜ˆì¸¡ 6:í‰ê°€
if "data" not in st.session_state:
    st.session_state.data = {"merged": None}  # ë‹¨ì¼ íŒŒì¼ë§Œ ì €ì¥
if "preprocess" not in st.session_state:
    st.session_state.preprocess = {"imputer": None, "scaler": None, "encoders": None, "feature_cols": None, "target_col": None}
if "models" not in st.session_state:
    # æ¨¡å‹ï¼šregressionï¼ˆíšŒê·€ë¶„ì„ï¼‰ã€decision_treeï¼ˆì˜ì‚¬ê²°ì •ë‚˜ë¬´ï¼‰
    st.session_state.models = {"regression": None, "decision_tree": None, "mixed_weights": {"regression": 0.3, "decision_tree": 0.7}}
if "task" not in st.session_state:
    st.session_state.task = "logit"  # ê¸°ë³¸ê°’ logitï¼ˆë¶„ë¥˜ï¼‰ï¼Œì˜ì‚¬ê²°ì •ë‚˜ë¬´ï¼ˆíšŒê·€ï¼‰ë¡œ ì „í™˜ ê°€ëŠ¥

# ----------------------
# 2. ì‚¬ì´ë“œë°”ï¼šë‹¨ê³„å¯¼èˆª + í•µì‹¬ ì„¤ì •
# ----------------------
st.sidebar.title("ğŸ“Œ í•˜ì´ë¸Œë¦¬ë“œëª¨í˜• ì‘ì—… íë¦„")
st.sidebar.divider()

# ë‹¨ê³„å¯¼èˆª ë²„íŠ¼ï¼ˆæ–°å¢ã€Œë°ì´í„° ì‹œê°í™”ã€ë‹¨ê³„ï¼‰
steps = ["ì´ˆê¸° ì„¤ì •", "ë°ì´í„° ì—…ë¡œë“œ", "ë°ì´í„° ì‹œê°í™”", "ë°ì´í„° ì „ì²˜ë¦¬", "ëª¨ë¸ í•™ìŠµ", "ëª¨ë¸ ì˜ˆì¸¡", "ì„±ëŠ¥ í‰ê°€"]
for i, step_name in enumerate(steps):
    if st.sidebar.button(step_name, key=f"btn_{i}"):
        st.session_state.step = i

# í•µì‹¬ ì„¤ì •ï¼ˆì‘ì—… ìœ í˜• + í˜¼í•© ê°€ì¤‘ì¹˜ï¼‰
st.sidebar.divider()
st.sidebar.subheader("í•µì‹¬ ì„¤ì •")
st.session_state.task = st.sidebar.radio("ì‘ì—… ìœ í˜•", options=["logit", "ì˜ì‚¬ê²°ì •ë‚˜ë¬´"], index=0)

if st.session_state.step >= 4:  # ëª¨ë¸ í•™ìŠµ í›„ ê°€ì¤‘ì¹˜ ì¡°ì • ê°€ëŠ¥
    st.sidebar.subheader("í•˜ì´ë¸Œë¦¬ë“œëª¨í˜• ê°€ì¤‘ì¹˜")
    reg_weight = st.sidebar.slider(
        "íšŒê·€ ë¶„ì„ ê°€ì¤‘ì¹˜ï¼ˆí•´ì„ë ¥ ê°•í•¨ï¼‰",
        min_value=0.0, max_value=1.0, value=st.session_state.models["mixed_weights"]["regression"], step=0.1
    )
    st.session_state.models["mixed_weights"]["regression"] = reg_weight
    st.session_state.models["mixed_weights"]["decision_tree"] = 1 - reg_weight
    st.sidebar.text(f"ì˜ì‚¬ê²°ì •ë‚˜ë¬´ ê°€ì¤‘ì¹˜ï¼ˆì •í™•ë„ ë†’ìŒï¼‰ï¼š{1 - reg_weight:.1f}")

# ----------------------
# 3. ë©”ì¸ í˜ì´ì§€ï¼šë‹¨ê³„ë³„ ë‚´ìš© í‘œì‹œ
# ----------------------
st.title("ğŸ“Š í•˜ì´ë¸Œë¦¬ë“œëª¨í˜• ë™ì  ë°°í¬ í”„ë ˆì„ì›Œí¬")
st.markdown("**ë‹¨ì¼ ì›ë³¸ ë°ì´í„° íŒŒì¼ ì—…ë¡œë“œ í›„ï¼Œì‹œê°í™”â†’ì „ì²˜ë¦¬â†’í•™ìŠµâ†’ì˜ˆì¸¡ ì „ê³¼ì •ì„ í•œ ë²ˆì— ì™„ì„±**")
st.markdown("### ğŸ§© í•µì‹¬ ëª¨ë¸ï¼šíšŒê·€ ë¶„ì„ï¼ˆRegressionï¼‰+ ì˜ì‚¬ê²°ì •ë‚˜ë¬´ï¼ˆDecision Treeï¼‰")
st.divider()

# ==============================================================================
# ë©”ì¸ ë¡œì§ ì‹œì‘
# ==============================================================================

# ----------------------
# ë‹¨ê³„ 0ï¼šì´ˆê¸° ì„¤ì •ï¼ˆì•ˆë‚´ í˜ì´ì§€ï¼‰
# ----------------------
if st.session_state.step == 0:
    st.subheader("ğŸ‰ í•˜ì´ë¸Œë¦¬ë“œëª¨í˜• ë™ì  í”„ë ˆì„ì›Œí¬ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤")
    st.markdown("""
    ë³¸ í”„ë ˆì„ì›Œí¬ëŠ” **ë°ì´í„° ìˆ˜ë ¹ í›„ ì§ì ‘ ì—…ë¡œë“œí•˜ì—¬ ì‚¬ìš©**í•  ìˆ˜ ìˆìœ¼ë©°ï¼Œì‚¬ì „ ì „ì²˜ë¦¬ë‚˜ ëª¨ë¸ í•™ìŠµì´ í•„ìš” ì—†ìŠµë‹ˆë‹¤. í•µì‹¬ íë¦„ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤ï¼š
    
    1. **ë°ì´í„° ì—…ë¡œë“œ**ï¼šë‹¨ì¼ ì›ë³¸ íŒŒì¼ï¼ˆCSV/Parquet/Excelï¼‰ì„ ì—…ë¡œë“œ
    2. **ë°ì´í„° ì‹œê°í™”**ï¼šë²”ì£¼í˜• ë³€ìˆ˜ì™€ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë¥¼ ì„ íƒí•˜ì—¬ ë‹¤ì–‘í•œ ê·¸ë˜í”„ë¡œ ë°ì´í„° íƒìƒ‰
    3. **ë°ì´í„° ì „ì²˜ë¦¬**ï¼šê²°ì¸¡ê°’ ì±„ìš°ê¸°ã€ë²”ì£¼í˜• íŠ¹ì§• ì¸ì½”ë”©
    4. **ëª¨ë¸ í•™ìŠµ**ï¼šã€ŒíšŒê·€ ë¶„ì„+ì˜ì‚¬ê²°ì •ë‚˜ë¬´ã€í•˜ì´ë¸Œë¦¬ë“œëª¨í˜• í•™ìŠµ
    5. **ëª¨ë¸ ì˜ˆì¸¡**ï¼šë‹¨ì¼ ë°ì´í„° ì…ë ¥ ë˜ëŠ” ì¼ê´„ ì—…ë¡œë“œ ì˜ˆì¸¡ì„ ì§€ì›
    6. **ì„±ëŠ¥ í‰ê°€**ï¼ší•˜ì´ë¸Œë¦¬ë“œëª¨í˜•ê³¼ ë‹¨ì¼ ëª¨í˜•ì˜ ì„±ëŠ¥ì„ ë¹„êµ
    
    ### ì ìš© ê°€ëŠ¥ í™˜ê²½
    - logit ì‘ì—…ï¼ˆë¶„ë¥˜ï¼‰ï¼šì‚¬ìš©ìê°€ ì„œë¹„ìŠ¤ë¥¼ ìˆ˜ë½í• ì§€ ì—¬ë¶€ã€ìœ„ë°˜ ì—¬ë¶€ç­‰ ì´ì§„ ì˜ˆì¸¡ï¼ˆëª¨ë¸ï¼šë¡œì§€ìŠ¤í‹± íšŒê·€+ë¶„ë¥˜ ì˜ì‚¬ê²°ì •ë‚˜ë¬´ï¼‰
    - ì˜ì‚¬ê²°ì •ë‚˜ë¬´ ì‘ì—…ï¼ˆíšŒê·€ï¼‰ï¼šíŒë§¤ëŸ‰ã€ê¸ˆì•¡ã€í‰ì ç­‰ ì—°ì†ê°’ ì˜ˆì¸¡ï¼ˆëª¨ë¸ï¼šì„ í˜• íšŒê·€+íšŒê·€ ì˜ì‚¬ê²°ì •ë‚˜ë¬´ï¼‰
    
    ### ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ **ã€Œ1. ë°ì´í„° ì—…ë¡œë“œã€**ë¥¼ ì„ íƒí•˜ì—¬ ì‹œì‘í•˜ì„¸ìš”!
    """)

# ----------------------
# ë‹¨ê³„ 1ï¼šë°ì´í„° ì—…ë¡œë“œ (ì¸ì½”ë”© ìë™ í•´ê²° ë²„ì „)
# ----------------------
elif st.session_state.step == 1:
    st.subheader("ğŸ“¤ ë°ì´í„° ì—…ë¡œë“œ")
    
    tab1, tab2 = st.tabs(["ğŸ“‚ ë‚´ íŒŒì¼ ì—…ë¡œë“œ", "ğŸ’¾ ì„œë²„ ê¸°ë³¸ ë°ì´í„° ì‚¬ìš©"])
    
    # ì¸ì½”ë”© ì²˜ë¦¬ë¥¼ ìœ„í•œ ë‚´ë¶€ í•¨ìˆ˜
    def load_csv_safe(file_buffer):
        # ì‹œë„í•  ì¸ì½”ë”© ëª©ë¡ (ìˆœì„œëŒ€ë¡œ ì‹œë„)
        encodings = ['utf-8', 'cp949', 'euc-kr', 'utf-8-sig', 'latin1']
        
        for enc in encodings:
            try:
                file_buffer.seek(0) # íŒŒì¼ í¬ì¸í„° ì´ˆê¸°í™”
                df = pd.read_csv(file_buffer, encoding=enc)
                return df, enc # ì„±ê³µí•˜ë©´ ë°ì´í„°ì™€ ì¸ì½”ë”© ë°˜í™˜
            except UnicodeDecodeError:
                continue # ì‹¤íŒ¨í•˜ë©´ ë‹¤ìŒ ì¸ì½”ë”© ì‹œë„
            except Exception as e:
                return None, str(e) # ê¸°íƒ€ ì—ëŸ¬
        return None, "ëª¨ë“  ì¸ì½”ë”© ì‹œë„ ì‹¤íŒ¨"

    with tab1:
        st.markdown("ì§€ì› í˜•ì‹ï¼šCSVã€Parquetã€Excelï¼ˆ.xlsx/.xlsï¼‰")
        uploaded_file = st.file_uploader("ë°ì´í„° íŒŒì¼ ì„ íƒ", type=["csv", "parquet", "xlsx", "xls"], key="single_file")
        
        if uploaded_file:
            try:
                df = None
                # í™•ì¥ìë³„ ë¡œë“œ
                if uploaded_file.name.endswith('.csv'):
                    df, enc_used = load_csv_safe(uploaded_file)
                    if df is None:
                        st.error(f"âŒ CSV íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {enc_used}")
                    else:
                        st.caption(f"â„¹ï¸ ê°ì§€ëœ ì¸ì½”ë”©: {enc_used}")
                        
                elif uploaded_file.name.endswith('.parquet'):
                    df = pd.read_parquet(uploaded_file)
                else:
                    df = pd.read_excel(uploaded_file)
                
                if df is not None:
                    # ì¸ë±ìŠ¤ ì´ˆê¸°í™” (ì „ì²˜ë¦¬ ì—ëŸ¬ ë°©ì§€ìš© í•„ìˆ˜)
                    df = df.reset_index(drop=True)
                    st.session_state.data["merged"] = df
                    st.success(f"âœ… íŒŒì¼ ì—…ë¡œë“œ ì„±ê³µ! ({len(df):,} í–‰)")
                
            except Exception as e:
                st.error(f"âŒ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    with tab2:
        DEFAULT_FILE_PATH = "combined_loan_data.csv" 
        st.info(f"ğŸ’¡ **ê¸°ë³¸ ë°ì´í„° ì„¤ëª…**: ëŒ€ì¶œ ê´€ë ¨ í†µí•© ë°ì´í„° (`{DEFAULT_FILE_PATH}`)")
        
        if st.button("ê¸°ë³¸ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°", type="primary"):
            if os.path.exists(DEFAULT_FILE_PATH):
                # ê¸°ë³¸ íŒŒì¼ë„ ì•ˆì „í•˜ê²Œ ë¡œë“œ ì‹œë„
                with open(DEFAULT_FILE_PATH, 'rb') as f:
                    df_default, enc_used = load_csv_safe(f)
                
                if df_default is not None:
                    st.session_state.data["merged"] = df_default.reset_index(drop=True)
                    st.success(f"âœ… ê¸°ë³¸ ë°ì´í„° ë¡œë“œ ì„±ê³µ! ({len(df_default):,} í–‰, ì¸ì½”ë”©: {enc_used})")
                    st.rerun()
                else:
                    st.error("âŒ ê¸°ë³¸ íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (ì¸ì½”ë”© ì˜¤ë¥˜).")
            else:
                st.error(f"âš ï¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {DEFAULT_FILE_PATH}")

    # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
    if st.session_state.data.get("merged") is not None:
        df_merged = st.session_state.data["merged"]
        st.divider()
        st.markdown(f"### âœ… í˜„ì¬ ë¡œë“œëœ ë°ì´í„° ({len(df_merged):,} í–‰)")
        st.dataframe(df_merged.head(5), use_container_width=True)
# ----------------------
# ë‹¨ê³„ 2ï¼šë°ì´í„° ì‹œê°í™” (ìˆ˜ì •ë¨)
# ----------------------
elif st.session_state.step == 2:
    st.subheader("ğŸ“Š ë°ì´í„° ì‹œê°í™”")
    
    # [ìˆ˜ì •ëœ ë¶€ë¶„] ë”°ì˜´í‘œê°€ ë‹«íˆì§€ ì•Šì•˜ë˜ ì—ëŸ¬ í•´ê²°
    if st.session_state.data["merged"] is None:
        st.warning("âš ï¸ ë¨¼ì € 'ë°ì´í„° ì—…ë¡œë“œ' ë‹¨ê³„ë¥¼ ì™„ë£Œí•˜ì„¸ìš”")
    else:
        df = st.session_state.data["merged"]
        
        # --- ë³€ìˆ˜ ì„ íƒ (Variable Selection) ---
        st.markdown("### 1ï¸âƒ£ ì‹œê°í™”í•  ë³€ìˆ˜ ì„ íƒ")
        all_cols = df.columns.tolist()
        default_selection = all_cols[:10] if len(all_cols) > 10 else all_cols
        
        selected_cols = st.multiselect(
            "ë¶„ì„ ëŒ€ìƒ ë³€ìˆ˜ ì„ íƒ",
            options=all_cols,
            default=default_selection
        )
        
        if not selected_cols:
            st.error("âš ï¸ ìµœì†Œ í•˜ë‚˜ ì´ìƒì˜ ë³€ìˆ˜ë¥¼ ì„ íƒí•´ì•¼ ì‹œê°í™”ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        else:
            df_vis = df[selected_cols]
            st.divider()
            
            # --- ê·¸ë˜í”„ ì„¤ì • ---
            st.markdown("### 2ï¸âƒ£ ê·¸ë˜í”„ ì„¤ì •")
            cat_cols = df_vis.select_dtypes(include=["object", "category"]).columns.tolist()
            num_cols = df_vis.select_dtypes(include=["int64", "float64"]).columns.tolist()
            
            col1, col2, col3 = st.columns(3)
            with col1:
                x_var = st.selectbox("ğŸ“‹ Xì¶• (ë²”ì£¼í˜•)", ["ì„ íƒ ì•ˆ í•¨"] + cat_cols)
                if x_var == "ì„ íƒ ì•ˆ í•¨": x_var = None
            with col2:
                y_var = st.selectbox("ğŸ“ˆ Yì¶• (ìˆ˜ì¹˜í˜•)", num_cols if num_cols else ["ì—†ìŒ"])
            with col3:
                graph_type = st.selectbox("ğŸ“Š ê·¸ë˜í”„ ìœ í˜•", [
                    "ë§‰ëŒ€ ê·¸ë˜í”„", "ë°•ìŠ¤ í”Œë¡¯", "ì‚°ì ë„", "íˆìŠ¤í† ê·¸ë¨", "ì„  ê·¸ë˜í”„"
                ])
            
            st.divider()
            
            # ì‹œê°í™” ì¶œë ¥
            if y_var and y_var != "ì—†ìŒ":
                try:
                    if graph_type == "íˆìŠ¤í† ê·¸ë¨":
                        fig = px.histogram(df_vis, x=y_var, color=x_var, title=f"{y_var} ë¶„í¬")
                    elif graph_type == "ë§‰ëŒ€ ê·¸ë˜í”„" and x_var:
                        avg_df = df_vis.groupby(x_var)[y_var].mean().reset_index()
                        fig = px.bar(avg_df, x=x_var, y=y_var, color=x_var, title=f"{x_var}ë³„ {y_var} í‰ê· ")
                    elif graph_type == "ë°•ìŠ¤ í”Œë¡¯" and x_var:
                        fig = px.box(df_vis, x=x_var, y=y_var, color=x_var, title=f"{x_var}ë³„ {y_var} ë¶„í¬")
                    elif graph_type == "ì‚°ì ë„" and x_var:
                        fig = px.scatter(df_vis, x=x_var, y=y_var, color=x_var, title=f"{x_var} vs {y_var}")
                    elif graph_type == "ì„  ê·¸ë˜í”„" and x_var:
                        line_df = df_vis.groupby(x_var)[y_var].mean().reset_index()
                        fig = px.line(line_df, x=x_var, y=y_var, markers=True, title=f"{x_var}ë³„ {y_var} ì¶”ì„¸")
                    else:
                        fig = None
                        st.info("Xì¶• ë³€ìˆ˜ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
                        
                    if fig:
                        st.plotly_chart(fig, use_container_width=True)
                except Exception as e:
                    st.error(f"ê·¸ë˜í”„ ìƒì„± ì˜¤ë¥˜: {e}")
            else:
                st.info("Yì¶• ë³€ìˆ˜ë¥¼ ì„ íƒí•˜ë©´ ê·¸ë˜í”„ê°€ í‘œì‹œë©ë‹ˆë‹¤.")

# ----------------------
# ë‹¨ê³„ 3ï¼šë°ì´í„° ì „ì²˜ë¦¬ & ë³€ìˆ˜ ì„ íƒ (ì„ íƒ ë³€ìˆ˜ë§Œ ì²˜ë¦¬)
# ----------------------
elif st.session_state.step == 3:
    st.subheader("ğŸ§¹ ë°ì´í„° ì „ì²˜ë¦¬ & ë³€ìˆ˜ ì„ íƒ")
    
    if st.session_state.data["merged"] is None:
        st.warning("âš ï¸ ë¨¼ì € 'ë°ì´í„° ì—…ë¡œë“œ' ë‹¨ê³„ë¥¼ ì™„ë£Œí•˜ì„¸ìš”.")
    else:
        # ì›ë³¸ ë°ì´í„° ì•ˆì „í•˜ê²Œ ê°€ì ¸ì˜¤ê¸° (ì¸ë±ìŠ¤ ë¦¬ì…‹)
        df_origin = st.session_state.data["merged"].copy().reset_index(drop=True)
        all_cols = df_origin.columns.tolist()

        st.markdown("### 1ï¸âƒ£ ë¶„ì„ì— ì‚¬ìš©í•  ë³€ìˆ˜ ì„ íƒ (Selection)")
        
        # 1. íƒ€ê²Ÿ ë³€ìˆ˜(Y) ì„ íƒ
        target_col = st.selectbox("ğŸ¯ íƒ€ê²Ÿ ë³€ìˆ˜ (Y) ì„ íƒ", options=all_cols)
        st.session_state.preprocess["target_col"] = target_col
        
        # 2. ì…ë ¥ ë³€ìˆ˜(X) ë‹¤ì¤‘ ì„ íƒ
        # íƒ€ê²Ÿì„ ì œì™¸í•œ ë‚˜ë¨¸ì§€ ë³€ìˆ˜ë“¤ì„ ì˜µì…˜ìœ¼ë¡œ ì œê³µ
        feature_candidates = [c for c in all_cols if c != target_col]
        
        # ê¸°ë³¸ì ìœ¼ë¡œ ë„ˆë¬´ ë§ì€ ì»¬ëŸ¼ì´ ì„ íƒë˜ì§€ ì•Šë„ë¡ ìƒìœ„ 10ê°œë§Œ ê¸°ë³¸ ì„ íƒ
        default_feats = feature_candidates[:10] if len(feature_candidates) > 10 else feature_candidates
        
        selected_features = st.multiselect(
            "ğŸ“‹ ì…ë ¥ ë³€ìˆ˜ (X) ì„ íƒ (ì´ ë³€ìˆ˜ë“¤ë§Œ ì „ì²˜ë¦¬í•©ë‹ˆë‹¤)",
            options=feature_candidates,
            default=default_feats
        )
        
        st.divider()

        if not selected_features:
            st.warning("âš ï¸ ë¶„ì„í•  ë³€ìˆ˜ë¥¼ ìµœì†Œ 1ê°œ ì´ìƒ ì„ íƒí•´ì£¼ì„¸ìš”.")
        else:
            # íƒ­ êµ¬ì„±
            tab_proc, tab_imp = st.tabs(["âš¡ ì„ íƒëœ ë³€ìˆ˜ ì „ì²˜ë¦¬ ì‹¤í–‰", "ğŸ“Š ë³€ìˆ˜ ì¤‘ìš”ë„ í™•ì¸"])
            
            with tab_proc:
                st.markdown(f"**ì„ íƒëœ {len(selected_features)}ê°œì˜ ë³€ìˆ˜ë§Œ ì¶”ì¶œí•˜ì—¬ ì „ì²˜ë¦¬ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.**")
                
                if st.button("ğŸš€ ì „ì²˜ë¦¬ ì‹œì‘ (ê²°ì¸¡ì¹˜+ì¸ì½”ë”©)", type="primary"):
                    with st.spinner("ë°ì´í„° ë³€í™˜ ì¤‘..."):
                        try:
                            # [í•µì‹¬ ë¡œì§] ì„ íƒëœ ì»¬ëŸ¼ë§Œ ë³„ë„ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ì¶”ì¶œ (Subset)
                            # ì¸ë±ìŠ¤ë¥¼ ë¦¬ì…‹í•˜ì—¬ ì°¨ì› ë¶ˆì¼ì¹˜ ë¬¸ì œ ì›ì²œ ì°¨ë‹¨
                            X = df_origin[selected_features].copy().reset_index(drop=True)
                            y = df_origin[target_col].copy().reset_index(drop=True)
                            
                            # ìˆ˜ì¹˜í˜•/ë²”ì£¼í˜• ìë™ ë¶„ë¥˜
                            num_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()
                            cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()
                            
                            # 1. ìˆ˜ì¹˜í˜• ì²˜ë¦¬ (Imputation + Scaling)
                            imputer = SimpleImputer(strategy='mean')
                            scaler = StandardScaler()
                            
                            if num_cols:
                                # fit_transform ê²°ê³¼ëŠ” numpy arrayì´ë¯€ë¡œ ë‹¤ì‹œ DFë¡œ ë³€í™˜í•´ì•¼ ì•ˆì „í•¨
                                X_num_arr = imputer.fit_transform(X[num_cols])
                                X_num_arr = scaler.fit_transform(X_num_arr)
                                X[num_cols] = pd.DataFrame(X_num_arr, columns=num_cols, index=X.index)
                            
                            # 2. ë²”ì£¼í˜• ì²˜ë¦¬ (Label Encoding)
                            encoders = {}
                            for col in cat_cols:
                                # ê²°ì¸¡ì¹˜ ì²˜ë¦¬ ë° ë¬¸ìì—´ ë³€í™˜
                                X[col] = X[col].fillna("Unknown").astype(str)
                                
                                le = LabelEncoder()
                                # Seriesë¡œ ë³€í™˜í•˜ì—¬ í• ë‹¹ (ì¸ë±ìŠ¤ ë§¤ì¹­ ë³´ì¥)
                                X[col] = pd.Series(le.fit_transform(X[col]), index=X.index)
                                encoders[col] = le
                            
                            # 3. ê²°ê³¼ ì €ì¥ (ì „ì—­ ìƒíƒœ)
                            st.session_state.preprocess["feature_cols"] = selected_features
                            st.session_state.preprocess["imputer"] = imputer if num_cols else None
                            st.session_state.preprocess["scaler"] = scaler if num_cols else None
                            st.session_state.preprocess["encoders"] = encoders
                            
                            st.session_state.data["X_processed"] = X
                            st.session_state.data["y_processed"] = y
                            
                            st.success("âœ… ì „ì²˜ë¦¬ ì™„ë£Œ! ë°ì´í„° í˜•ì‹ì´ ëª¨ë¸ í•™ìŠµì— ë§ê²Œ ë³€í™˜ë˜ì—ˆìŠµë‹ˆë‹¤.")
                            st.write("â–¼ ë³€í™˜ëœ ë°ì´í„° ë¯¸ë¦¬ë³´ê¸° (ìƒìœ„ 3í–‰)")
                            st.dataframe(X.head(3))
                            
                        except Exception as e:
                            st.error(f"âŒ ì „ì²˜ë¦¬ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                            st.warning("íŒ: ë°ì´í„°ì— ì„ì—¬ìˆëŠ” íŠ¹ìˆ˜ë¬¸ìë‚˜ ì¸ë±ìŠ¤ ë¬¸ì œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

            with tab_imp:
                if "X_processed" in st.session_state.data:
                    st.markdown("##### ğŸ§¬ ë³€ìˆ˜ ì¤‘ìš”ë„ (Feature Importance)")
                    if st.button("ì¤‘ìš”ë„ ë¶„ì„ ì‹¤í–‰"):
                        X_p = st.session_state.data["X_processed"]
                        y_p = st.session_state.data["y_processed"]
                        
                        # ê°„ë‹¨í•œ íŠ¸ë¦¬ ëª¨ë¸ë¡œ ì¤‘ìš”ë„ ì‚°ì¶œ
                        model = DecisionTreeClassifier(max_depth=5) if st.session_state.task == "logit" else DecisionTreeRegressor(max_depth=5)
                        model.fit(X_p, y_p)
                        
                        imp = pd.DataFrame({
                            "Feature": X_p.columns,
                            "Importance": model.feature_importances_
                        }).sort_values("Importance", ascending=False)
                        
                        fig = px.bar(imp, x="Importance", y="Feature", orientation='h', title="ë³€ìˆ˜ ì¤‘ìš”ë„ Top Features")
                        st.plotly_chart(fig, use_container_width=True)
                else:
                    st.info("ğŸ‘ˆ ë¨¼ì € [ì „ì²˜ë¦¬ ì‹¤í–‰] ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
# ----------------------
# ë‹¨ê³„ 4ï¼šëª¨ë¸ í•™ìŠµ
# ----------------------
elif st.session_state.step == 4:
    st.subheader("ğŸš€ í•˜ì´ë¸Œë¦¬ë“œëª¨í˜• í•™ìŠµ")
    
    if "X_processed" not in st.session_state.data or st.session_state.data["X_processed"] is None:
        st.warning("ë¨¼ì €ã€Œë°ì´í„° ì „ì²˜ë¦¬ã€ë‹¨ê³„ë¥¼ ì™„ë£Œí•˜ì„¸ìš”")
    else:
        X = st.session_state.data["X_processed"]
        y = st.session_state.data["y_processed"]
        
        st.markdown("### 1. í•™ìŠµ ì„¤ì •")
        col1, col2 = st.columns(2)
        with col1:
            test_size = st.slider("í…ŒìŠ¤íŠ¸ì…‹ ë¹„ìœ¨", 0.1, 0.4, 0.2, 0.05)
        with col2:
            st.info(f"í˜„ì¬ ì‘ì—… ìœ í˜•: **{st.session_state.task}**")
            
        # Stratify ë¡œì§
        stratify_param = None
        if st.session_state.task == "logit":
            if y.nunique() >= 2 and (y.value_counts() >= 2).all():
                stratify_param = y
                st.success("âœ… ì¸µí™” ì¶”ì¶œ(Stratified Sampling) ì ìš©ë¨")
            else:
                st.warning("âš ï¸ í´ë˜ìŠ¤ ë¶ˆê· í˜• ë˜ëŠ” ìƒ˜í”Œ ë¶€ì¡±ìœ¼ë¡œ ì¸µí™” ì¶”ì¶œ ë¯¸ì ìš©")
        
        X_train, X_test, y_train, y_test = train_test_split(
            X, y, test_size=test_size, random_state=42, stratify=stratify_param
        )
        
        # [ìˆ˜ì • 4] ê°€ì¤‘ì¹˜ ì„¤ì • ì¶”ê°€
        st.markdown("### 2. í•˜ì´ë¸Œë¦¬ë“œ ê°€ì¤‘ì¹˜ ì„¤ì •")
        w_col1, w_col2 = st.columns(2)
        with w_col1:
            reg_weight = st.slider("íšŒê·€ë¶„ì„(Logistic/Linear) ê°€ì¤‘ì¹˜", 0.0, 1.0, 0.5)
        with w_col2:
            st.metric("ì˜ì‚¬ê²°ì •ë‚˜ë¬´ ê°€ì¤‘ì¹˜", f"{1.0 - reg_weight:.1f}")
            
        # ëª¨ë¸ ì •ì˜
        if st.session_state.task == "logit":
            reg_model = LogisticRegression(max_iter=1000)
            dt_model = DecisionTreeClassifier(random_state=42, max_depth=10)
        else:
            reg_model = LinearRegression()
            dt_model = DecisionTreeRegressor(random_state=42, max_depth=10)
            
        if st.button("ëª¨ë¸ í•™ìŠµ ì‹œì‘", type="primary"):
            with st.spinner("ëª¨ë¸ í•™ìŠµ ì¤‘..."):
                try:
                    reg_model.fit(X_train, y_train)
                    dt_model.fit(X_train, y_train)
                    
                    st.session_state.models["regression"] = reg_model
                    st.session_state.models["decision_tree"] = dt_model
                    st.session_state.models["mixed_weights"] = {
                        "regression": reg_weight, "decision_tree": 1.0 - reg_weight
                    }
                    
                    st.session_state.data.update({
                        "X_train": X_train, "X_test": X_test, 
                        "y_train": y_train, "y_test": y_test
                    })
                    
                    st.success("âœ… ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!")
                    st.markdown(f"**í•™ìŠµ ë°ì´í„°**: {len(X_train):,}ê°œ | **í…ŒìŠ¤íŠ¸ ë°ì´í„°**: {len(X_test):,}ê°œ")
                    
                except Exception as e:
                    st.error(f"í•™ìŠµ ì‹¤íŒ¨: {str(e)}")

# ----------------------
# ë‹¨ê³„ 5ï¼šëª¨ë¸ ì˜ˆì¸¡
# ----------------------
elif st.session_state.step == 5:
    st.subheader("ğŸ¯ ëª¨ë¸ ì˜ˆì¸¡")
    
    if st.session_state.models["regression"] is None:
        st.warning("ë¨¼ì €ã€Œëª¨ë¸ í•™ìŠµã€ë‹¨ê³„ë¥¼ ì™„ë£Œí•˜ì„¸ìš”")
    else:
        def predict_pipeline(input_df):
            # 1. ì „ì²˜ë¦¬ ì ìš©
            preprocess = st.session_state.preprocess
            X = input_df.copy()
            
            num_cols = X.select_dtypes(include=["int64", "float64"]).columns
            cat_cols = X.select_dtypes(include=["object", "category"]).columns
            
            # ìˆ˜ì¹˜í˜• ë³€í™˜
            if preprocess["imputer"]:
                X[num_cols] = preprocess["imputer"].transform(X[num_cols])
                X[num_cols] = preprocess["scaler"].transform(X[num_cols])
            
            # ë²”ì£¼í˜• ë³€í™˜
            for col in cat_cols:
                X[col] = X[col].fillna("ì•Œ ìˆ˜ ì—†ìŒ").astype(str)
                encoder = preprocess["encoders"].get(col)
                if encoder:
                    if isinstance(encoder, LabelEncoder):
                        # ë¯¸ì§€ì˜ ê°’ ì²˜ë¦¬
                        known_classes = set(encoder.classes_)
                        X[col] = X[col].apply(lambda x: x if x in known_classes else "ì•Œ ìˆ˜ ì—†ìŒ")
                        # "ì•Œ ìˆ˜ ì—†ìŒ"ì´ í´ë˜ìŠ¤ì— ì—†ìœ¼ë©´ ì¶”ê°€ (ì„ì‹œ ì²˜ë¦¬)
                        if "ì•Œ ìˆ˜ ì—†ìŒ" not in known_classes:
                             # LabelEncoderëŠ” ë™ì  ì¶”ê°€ê°€ ì–´ë ¤ìš°ë¯€ë¡œ 0ìœ¼ë¡œ ëŒ€ì²´í•˜ê±°ë‚˜ ì˜ˆì™¸ì²˜ë¦¬ í•„ìš”
                             # ì—¬ê¸°ì„œëŠ” í¸ì˜ìƒ ê°€ì¥ ë¹ˆë„ ë†’ì€ ê°’ìœ¼ë¡œ ëŒ€ì²´ ê°€ì • ë˜ëŠ” 0
                             pass 
                        # transform ì‹œ ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•´ try-except ê¶Œì¥
                        try:
                            X[col] = encoder.transform(X[col])
                        except:
                            X[col] = 0
                    else:
                        # OneHotEncoder
                        ohe, ohe_cols = encoder
                        ohe_result = ohe.transform(X[[col]])
                        X = pd.concat([X.drop(col, axis=1), pd.DataFrame(ohe_result, columns=ohe_cols)], axis=1)
            
            # ì»¬ëŸ¼ ìˆœì„œ ë§ì¶”ê¸°
            missing_cols = set(preprocess["feature_cols"]) - set(X.columns)
            for c in missing_cols:
                X[c] = 0
            X = X[preprocess["feature_cols"]]
            
            # 2. ì˜ˆì¸¡
            reg_model = st.session_state.models["regression"]
            dt_model = st.session_state.models["decision_tree"]
            weights = st.session_state.models["mixed_weights"]
            
            if st.session_state.task == "logit":
                reg_p = reg_model.predict_proba(X)[:, 1]
                dt_p = dt_model.predict_proba(X)[:, 1]
                mixed_p = weights["regression"] * reg_p + weights["decision_tree"] * dt_p
                pred = (mixed_p >= 0.5).astype(int)
                return pred, mixed_p
            else:
                reg_p = reg_model.predict(X)
                dt_p = dt_model.predict(X)
                mixed_p = weights["regression"] * reg_p + weights["decision_tree"] * dt_p
                return mixed_p, None

        mode = st.radio("ì˜ˆì¸¡ ë°©ì‹", ["ë‹¨ì¼ ë°ì´í„° ì…ë ¥", "ì¼ê´„ ì—…ë¡œë“œ (CSV)"])
        
        if mode == "ë‹¨ì¼ ë°ì´í„° ì…ë ¥":
            st.markdown("#### ë°ì´í„° ì…ë ¥")
            feature_cols = st.session_state.preprocess["feature_cols"]
            # ì›ë³¸ ë°ì´í„°í”„ë ˆì„ êµ¬ì¡° ì°¸ì¡° (ì¸ì½”ë”© ì „)
            original_features = [c for c in st.session_state.data["merged"].columns 
                               if c not in [st.session_state.preprocess["target_col"]]]
            
            input_data = {}
            with st.form("pred_form"):
                cols = st.columns(3)
                for i, col in enumerate(original_features[:9]): # ìµœëŒ€ 9ê°œë§Œ í‘œì‹œ
                    with cols[i % 3]:
                        # ì›ë³¸ ë°ì´í„° íƒ€ì… í™•ì¸
                        col_type = st.session_state.data["merged"][col].dtype
                        if pd.api.types.is_numeric_dtype(col_type):
                            input_data[col] = st.number_input(col, value=0.0)
                        else:
                            opts = st.session_state.data["merged"][col].dropna().unique()
                            input_data[col] = st.selectbox(col, options=opts)
                submit = st.form_submit_button("ì˜ˆì¸¡í•˜ê¸°")
            
            if submit:
                input_df = pd.DataFrame([input_data])
                pred, proba = predict_pipeline(input_df)
                st.divider()
                if st.session_state.task == "logit":
                    st.metric("ì˜ˆì¸¡ ê²°ê³¼", "ì–‘ì„±(Positive)" if pred[0]==1 else "ìŒì„±(Negative)")
                    st.metric("í™•ë¥ ", f"{proba[0]:.2%}")
                else:
                    st.metric("ì˜ˆì¸¡ ê°’", f"{pred[0]:.4f}")
                    
        else:
            up_file = st.file_uploader("CSV ì—…ë¡œë“œ", type=["csv"])
            if up_file:
                batch_df = pd.read_csv(up_file)
                if st.button("ì¼ê´„ ì˜ˆì¸¡ ì‹œì‘"):
                    pred, proba = predict_pipeline(batch_df)
                    batch_df["Predicted"] = pred
                    if proba is not None:
                        batch_df["Probability"] = proba
                    st.dataframe(batch_df.head())
                    st.download_button("ê²°ê³¼ ë‹¤ìš´ë¡œë“œ", batch_df.to_csv().encode('utf-8'), "prediction.csv")

# ----------------------
# ë‹¨ê³„ 6ï¼šì„±ëŠ¥ í‰ê°€
# ----------------------
elif st.session_state.step == 6:
    st.subheader("ğŸ“ˆ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€")
    
    if st.session_state.models["regression"] is None:
        st.warning("ë¨¼ì €ã€Œëª¨ë¸ í•™ìŠµã€ë‹¨ê³„ë¥¼ ì™„ë£Œí•˜ì„¸ìš”")
    else:
        X_test = st.session_state.data["X_test"]
        y_test = st.session_state.data["y_test"]
        
        reg_model = st.session_state.models["regression"]
        dt_model = st.session_state.models["decision_tree"]
        weights = st.session_state.models["mixed_weights"]
        
        if st.session_state.task == "logit":
            # í™•ë¥  ê³„ì‚°
            reg_p = reg_model.predict_proba(X_test)[:, 1]
            dt_p = dt_model.predict_proba(X_test)[:, 1]
            mixed_p = weights["regression"] * reg_p + weights["decision_tree"] * dt_p
            
            # ì˜ˆì¸¡ê°’
            reg_pred = reg_model.predict(X_test)
            dt_pred = dt_model.predict(X_test)
            mixed_pred = (mixed_p >= 0.5).astype(int)
            
            # í‰ê°€ í•¨ìˆ˜
            def get_metrics(y, pred, proba):
                return {
                    "ACC": accuracy_score(y, pred),
                    "AUC": auc(*roc_curve(y, proba)[:2])
                }
            
            m1 = get_metrics(y_test, reg_pred, reg_p)
            m2 = get_metrics(y_test, dt_pred, dt_p)
            m3 = get_metrics(y_test, mixed_pred, mixed_p)
            
            metrics = pd.DataFrame([m1, m2, m3], index=["íšŒê·€ë¶„ì„", "ì˜ì‚¬ê²°ì •ë‚˜ë¬´", "í•˜ì´ë¸Œë¦¬ë“œ"])
            st.table(metrics)
            
            # ROC ê³¡ì„ 
            fpr, tpr, _ = roc_curve(y_test, mixed_p)
            fig = px.area(x=fpr, y=tpr, title=f"ROC Curve (Hybrid AUC={m3['AUC']:.3f})", 
                        labels=dict(x="False Positive Rate", y="True Positive Rate"))
            fig.add_shape(type='line', line=dict(dash='dash'), x0=0, x1=1, y0=0, y1=1)
            st.plotly_chart(fig, use_container_width=True)
            
        else:
            # íšŒê·€ í‰ê°€
            reg_pred = reg_model.predict(X_test)
            dt_pred = dt_model.predict(X_test)
            mixed_pred = weights["regression"] * reg_pred + weights["decision_tree"] * dt_pred
            
            def get_reg_metrics(y, pred):
                return {
                    "MAE": mean_absolute_error(y, pred),
                    "RMSE": np.sqrt(mean_squared_error(y, pred)),
                    "R2": r2_score(y, pred)
                }
            
            m1 = get_reg_metrics(y_test, reg_pred)
            m2 = get_reg_metrics(y_test, dt_pred)
            m3 = get_reg_metrics(y_test, mixed_pred)
            
            metrics = pd.DataFrame([m1, m2, m3], index=["ì„ í˜•íšŒê·€", "ì˜ì‚¬ê²°ì •ë‚˜ë¬´", "í•˜ì´ë¸Œë¦¬ë“œ"])
            st.table(metrics)
            
            # ì˜ˆì¸¡ vs ì‹¤ì œ
            fig = px.scatter(x=y_test, y=mixed_pred, title="ì‹¤ì œê°’ vs ì˜ˆì¸¡ê°’ (Hybrid)", 
                           labels={"x": "ì‹¤ì œê°’", "y": "ì˜ˆì¸¡ê°’"})
            fig.add_shape(type='line', line=dict(dash='dash', color='red'), 
                        x0=y_test.min(), x1=y_test.max(), y0=y_test.min(), y1=y_test.max())
            st.plotly_chart(fig, use_container_width=True)
            
        # ì¤‘ìš”ë„ (Tree ê¸°ì¤€)
        if hasattr(dt_model, "feature_importances_"):
            st.markdown("### ğŸŒ³ ë³€ìˆ˜ ì¤‘ìš”ë„ (ì˜ì‚¬ê²°ì •ë‚˜ë¬´ ê¸°ì¤€)")
            imp_df = pd.DataFrame({
                "Feature": st.session_state.preprocess["feature_cols"],
                "Importance": dt_model.feature_importances_
            }).sort_values("Importance", ascending=False).head(10)
            
            fig_imp = px.bar(imp_df, x="Importance", y="Feature", orientation='h', title="Top 10 Feature Importance")
            st.plotly_chart(fig_imp, use_container_width=True)
