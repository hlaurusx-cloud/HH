import streamlit as st
import pandas as pd
import numpy as np
import os
import joblib
import plotly.express as px
import plotly.graph_objects as go
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor
from sklearn.metrics import (
    accuracy_score, auc, roc_curve, confusion_matrix,
    mean_absolute_error, mean_squared_error, r2_score
)
import warnings
warnings.filterwarnings("ignore")

# ----------------------
# 1. í˜ì´ì§€ ê¸°ë³¸ ì„¤ì • (FIX: set_page_configëŠ” ë§¨ ì²˜ìŒì— ë”± í•œ ë²ˆë§Œ í˜¸ì¶œí•´ì•¼ í•©ë‹ˆë‹¤)
# ----------------------
st.set_page_config(
    page_title="í•˜ì´ë¸Œë¦¬ë“œëª¨í˜• ë™ì  í”„ë ˆì„ì›Œí¬ï¼ˆì˜ì‚¬ê²°ì •ë‚˜ë¬´+íšŒê·€ë¶„ì„ï¼‰",
    page_icon="ğŸ“Š",
    layout="wide"
)

# ì „ì—­ ìƒíƒœ ê´€ë¦¬ï¼ˆê° ë‹¨ê³„ ë°ì´í„°/ëª¨ë¸ ì €ì¥ï¼Œìƒˆë¡œê³ ì¹¨ ì‹œ ì†ì‹¤ ë°©ì§€ï¼‰
if "step" not in st.session_state:
    st.session_state.step = 0  # 0:ì´ˆê¸°í™”ë©´ 1:ë°ì´í„°ì—…ë¡œë“œ 2:ë°ì´í„°ì‹œê°í™” 3:ë°ì´í„°ì „ì²˜ë¦¬ 4:ëª¨ë¸í•™ìŠµ 5:ì˜ˆì¸¡ 6:í‰ê°€
if "data" not in st.session_state:
    st.session_state.data = {"merged": None}  # ë‹¨ì¼ íŒŒì¼ë§Œ ì €ì¥
if "preprocess" not in st.session_state:
    st.session_state.preprocess = {"imputer": None, "scaler": None, "encoders": None, "feature_cols": None, "target_col": None}
if "models" not in st.session_state:
    # æ¨¡å‹ï¼šregressionï¼ˆíšŒê·€ë¶„ì„ï¼‰ã€decision_treeï¼ˆì˜ì‚¬ê²°ì •ë‚˜ë¬´ï¼‰
    st.session_state.models = {"regression": None, "decision_tree": None, "mixed_weights": {"regression": 0.3, "decision_tree": 0.7}}
if "task" not in st.session_state:
    st.session_state.task = "logit"  # ê¸°ë³¸ê°’ logitï¼ˆë¶„ë¥˜ï¼‰ï¼Œì˜ì‚¬ê²°ì •ë‚˜ë¬´ï¼ˆíšŒê·€ï¼‰ë¡œ ì „í™˜ ê°€ëŠ¥

# ----------------------
# 2. ì‚¬ì´ë“œë°”ï¼šë‹¨ê³„å¯¼èˆª + í•µì‹¬ ì„¤ì •
# ----------------------
st.sidebar.title("ğŸ“Œ í•˜ì´ë¸Œë¦¬ë“œëª¨í˜• ì‘ì—… íë¦„")
st.sidebar.divider()

# ë‹¨ê³„å¯¼èˆª ë²„íŠ¼
steps = ["ì´ˆê¸° ì„¤ì •", "ë°ì´í„° ì—…ë¡œë“œ", "ë°ì´í„° ì‹œê°í™”", "ë°ì´í„° ì „ì²˜ë¦¬", "ëª¨ë¸ í•™ìŠµ", "ëª¨ë¸ ì˜ˆì¸¡", "ì„±ëŠ¥ í‰ê°€"]
for i, step_name in enumerate(steps):
    if st.sidebar.button(step_name, key=f"btn_{i}"):
        st.session_state.step = i

# í•µì‹¬ ì„¤ì •ï¼ˆì‘ì—… ìœ í˜• + í˜¼í•© ê°€ì¤‘ì¹˜ï¼‰
st.sidebar.divider()
st.sidebar.subheader("í•µì‹¬ ì„¤ì •")
# Fix: index calculation to avoid error
current_idx = 0 if st.session_state.task == "logit" else 1
new_task = st.sidebar.radio("ì‘ì—… ìœ í˜•", options=["logit", "ì˜ì‚¬ê²°ì •ë‚˜ë¬´"], index=current_idx)
st.session_state.task = new_task

if st.session_state.step >= 4:  # ëª¨ë¸ í•™ìŠµ í›„ ê°€ì¤‘ì¹˜ ì¡°ì • ê°€ëŠ¥
    st.sidebar.subheader("í•˜ì´ë¸Œë¦¬ë“œëª¨í˜• ê°€ì¤‘ì¹˜")
    reg_weight = st.sidebar.slider(
        "íšŒê·€ ë¶„ì„ ê°€ì¤‘ì¹˜ï¼ˆí•´ì„ë ¥ ê°•í•¨ï¼‰",
        min_value=0.0, max_value=1.0, value=st.session_state.models["mixed_weights"]["regression"], step=0.1
    )
    st.session_state.models["mixed_weights"]["regression"] = reg_weight
    st.session_state.models["mixed_weights"]["decision_tree"] = 1 - reg_weight
    st.sidebar.text(f"ì˜ì‚¬ê²°ì •ë‚˜ë¬´ ê°€ì¤‘ì¹˜ï¼ˆì •í™•ë„ ë†’ìŒï¼‰ï¼š{1 - reg_weight:.1f}")

# ----------------------
# 3. ë©”ì¸ í˜ì´ì§€ï¼šë‹¨ê³„ë³„ ë‚´ìš© í‘œì‹œ
# ----------------------
st.title("ğŸ“Š í•˜ì´ë¸Œë¦¬ë“œëª¨í˜• ë™ì  ë°°í¬ í”„ë ˆì„ì›Œí¬")
st.markdown("**ë‹¨ì¼ ì›ë³¸ ë°ì´í„° íŒŒì¼ ì—…ë¡œë“œ í›„ï¼Œì‹œê°í™”â†’ì „ì²˜ë¦¬â†’í•™ìŠµâ†’ì˜ˆì¸¡ ì „ê³¼ì •ì„ í•œ ë²ˆì— ì™„ì„±**")
st.markdown("### ğŸ§© í•µì‹¬ ëª¨ë¸ï¼šíšŒê·€ ë¶„ì„ï¼ˆRegressionï¼‰+ ì˜ì‚¬ê²°ì •ë‚˜ë¬´ï¼ˆDecision Treeï¼‰")
st.divider()

# ==============================================================================
# ë©”ì¸ ë¡œì§ ì‹œì‘
# ==============================================================================

# ----------------------
#  ë‹¨ê³„ 0ï¼šì´ˆê¸° ì„¤ì •ï¼ˆì•ˆë‚´ í˜ì´ì§€ï¼‰
# ----------------------
if st.session_state.step == 0:
    st.subheader("ğŸ‰ í•˜ì´ë¸Œë¦¬ë“œëª¨í˜• ë™ì  í”„ë ˆì„ì›Œí¬ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤")
    st.markdown("""
    ë³¸ í”„ë ˆì„ì›Œí¬ëŠ” **ë°ì´í„° ìˆ˜ë ¹ í›„ ì§ì ‘ ì—…ë¡œë“œí•˜ì—¬ ì‚¬ìš©**í•  ìˆ˜ ìˆìœ¼ë©°ï¼Œì‚¬ì „ ì „ì²˜ë¦¬ë‚˜ ëª¨ë¸ í•™ìŠµì´ í•„ìš” ì—†ìŠµë‹ˆë‹¤. í•µì‹¬ íë¦„ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤ï¼š
    
    1. **ë°ì´í„° ì—…ë¡œë“œ**ï¼šë‹¨ì¼ ì›ë³¸ íŒŒì¼ï¼ˆCSV/Parquet/Excelï¼‰ì„ ì—…ë¡œë“œ
    2. **ë°ì´í„° ì‹œê°í™”**ï¼šë²”ì£¼í˜• ë³€ìˆ˜ì™€ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë¥¼ ì„ íƒí•˜ì—¬ ë‹¤ì–‘í•œ ê·¸ë˜í”„ë¡œ ë°ì´í„° íƒìƒ‰
    3. **ë°ì´í„° ì „ì²˜ë¦¬**ï¼šê²°ì¸¡ê°’ ì±„ìš°ê¸°ã€ë²”ì£¼í˜• íŠ¹ì§• ì¸ì½”ë”©
    4. **ëª¨ë¸ í•™ìŠµ**ï¼šã€ŒíšŒê·€ ë¶„ì„+ì˜ì‚¬ê²°ì •ë‚˜ë¬´ã€í•˜ì´ë¸Œë¦¬ë“œëª¨í˜• í•™ìŠµ
    5. **ëª¨ë¸ ì˜ˆì¸¡**ï¼šë‹¨ì¼ ë°ì´í„° ì…ë ¥ ë˜ëŠ” ì¼ê´„ ì—…ë¡œë“œ ì˜ˆì¸¡ì„ ì§€ì›
    6. **ì„±ëŠ¥ í‰ê°€**ï¼ší•˜ì´ë¸Œë¦¬ë“œëª¨í˜•ê³¼ ë‹¨ì¼ ëª¨í˜•ì˜ ì„±ëŠ¥ì„ ë¹„êµ
    
    ### ì ìš© ê°€ëŠ¥ í™˜ê²½
    - logit ì‘ì—…ï¼ˆë¶„ë¥˜ï¼‰ï¼šì‚¬ìš©ìê°€ ì„œë¹„ìŠ¤ë¥¼ ìˆ˜ë½í• ì§€ ì—¬ë¶€ã€ìœ„ë°˜ ì—¬ë¶€ç­‰ ì´ì§„ ì˜ˆì¸¡ï¼ˆëª¨ë¸ï¼šë¡œì§€ìŠ¤í‹± íšŒê·€+ë¶„ë¥˜ ì˜ì‚¬ê²°ì •ë‚˜ë¬´ï¼‰
    - ì˜ì‚¬ê²°ì •ë‚˜ë¬´ ì‘ì—…ï¼ˆíšŒê·€ï¼‰ï¼šíŒë§¤ëŸ‰ã€ê¸ˆì•¡ã€í‰ì ç­‰ ì—°ì†ê°’ ì˜ˆì¸¡ï¼ˆëª¨ë¸ï¼šì„ í˜• íšŒê·€+íšŒê·€ ì˜ì‚¬ê²°ì •ë‚˜ë¬´ï¼‰
    
    ### ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ **ã€Œ1. ë°ì´í„° ì—…ë¡œë“œã€**ë¥¼ ì„ íƒí•˜ì—¬ ì‹œì‘í•˜ì„¸ìš”!
    """)

# ----------------------
#  ë‹¨ê³„ 1ï¼šë°ì´í„° ì—…ë¡œë“œ
# ----------------------
elif st.session_state.step == 1:
    st.subheader("ğŸ“¤ ë°ì´í„° ì—…ë¡œë“œ")
    
    tab1, tab2 = st.tabs(["ğŸ“‚ ë‚´ íŒŒì¼ ì—…ë¡œë“œ", "ğŸ’¾ ì„œë²„ ê¸°ë³¸ ë°ì´í„° ì‚¬ìš©"])
    
    def load_csv_safe(file_buffer):
        encodings = ['utf-8', 'cp949', 'euc-kr', 'utf-8-sig', 'latin1']
        for enc in encodings:
            try:
                file_buffer.seek(0)
                df = pd.read_csv(file_buffer, encoding=enc)
                return df, enc
            except UnicodeDecodeError:
                continue
            except Exception as e:
                return None, str(e)
        return None, "ëª¨ë“  ì¸ì½”ë”© ì‹œë„ ì‹¤íŒ¨"

    with tab1:
        st.markdown("ì§€ì› í˜•ì‹ï¼šCSVã€Parquetã€Excelï¼ˆ.xlsx/.xlsï¼‰")
        uploaded_file = st.file_uploader("ë°ì´í„° íŒŒì¼ ì„ íƒ", type=["csv", "parquet", "xlsx", "xls"], key="single_file")
        
        if uploaded_file:
            try:
                df = None
                if uploaded_file.name.endswith('.csv'):
                    df, enc_used = load_csv_safe(uploaded_file)
                    if df is None:
                        st.error(f"âŒ CSV íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {enc_used}")
                    else:
                        st.caption(f"â„¹ï¸ ê°ì§€ëœ ì¸ì½”ë”©: {enc_used}")
                        
                elif uploaded_file.name.endswith('.parquet'):
                    df = pd.read_parquet(uploaded_file)
                else:
                    df = pd.read_excel(uploaded_file)
                
                if df is not None:
                    df = df.reset_index(drop=True)
                    st.session_state.data["merged"] = df
                    st.success(f"âœ… íŒŒì¼ ì—…ë¡œë“œ ì„±ê³µ! ({len(df):,} í–‰)")
                
            except Exception as e:
                st.error(f"âŒ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    with tab2:
        DEFAULT_FILE_PATH = "combined_loan_data.csv" 
        st.info(f"ğŸ’¡ **ê¸°ë³¸ ë°ì´í„° ì„¤ëª…**: ëŒ€ì¶œ ê´€ë ¨ í†µí•© ë°ì´í„° (`{DEFAULT_FILE_PATH}`)")
        
        if st.button("ê¸°ë³¸ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°", type="primary"):
            if os.path.exists(DEFAULT_FILE_PATH):
                with open(DEFAULT_FILE_PATH, 'rb') as f:
                    df_default, enc_used = load_csv_safe(f)
                
                if df_default is not None:
                    st.session_state.data["merged"] = df_default.reset_index(drop=True)
                    st.success(f"âœ… ê¸°ë³¸ ë°ì´í„° ë¡œë“œ ì„±ê³µ! ({len(df_default):,} í–‰, ì¸ì½”ë”©: {enc_used})")
                    st.rerun()
                else:
                    st.error("âŒ ê¸°ë³¸ íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (ì¸ì½”ë”© ì˜¤ë¥˜).")
            else:
                st.error(f"âš ï¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {DEFAULT_FILE_PATH} (íŒŒì¼ì„ ì•±ê³¼ ê°™ì€ í´ë”ì— ë„£ì–´ì£¼ì„¸ìš”)")

    if st.session_state.data.get("merged") is not None:
        df_merged = st.session_state.data["merged"]
        st.divider()
        st.markdown(f"### âœ… í˜„ì¬ ë¡œë“œëœ ë°ì´í„° ({len(df_merged):,} í–‰)")
        st.dataframe(df_merged.head(5), width=None) # width fix

# ----------------------
#  ë‹¨ê³„ 2ï¼šë°ì´í„° ì‹œê°í™”
# ----------------------
elif st.session_state.step == 2:
    st.subheader("ğŸ“Š ë°ì´í„° ì‹œê°í™”")
    
    if st.session_state.data["merged"] is None:
        st.warning("âš ï¸ ë¨¼ì € 'ë°ì´í„° ì—…ë¡œë“œ' ë‹¨ê³„ë¥¼ ì™„ë£Œí•˜ì„¸ìš”")
    else:
        df = st.session_state.data["merged"]
        st.markdown("### 1ï¸âƒ£ ì‹œê°í™”í•  ë³€ìˆ˜ ì„ íƒ")
        all_cols = df.columns.tolist()
        default_selection = all_cols[:10] if len(all_cols) > 10 else all_cols
        
        selected_cols = st.multiselect(
            "ë¶„ì„ ëŒ€ìƒ ë³€ìˆ˜ ì„ íƒ",
            options=all_cols,
            default=default_selection
        )
        
        if not selected_cols:
            st.error("âš ï¸ ìµœì†Œ í•˜ë‚˜ ì´ìƒì˜ ë³€ìˆ˜ë¥¼ ì„ íƒí•´ì•¼ ì‹œê°í™”ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        else:
            df_vis = df[selected_cols]
            st.divider()
            
            st.markdown("### 2ï¸âƒ£ ê·¸ë˜í”„ ì„¤ì •")
            cat_cols = df_vis.select_dtypes(include=["object", "category"]).columns.tolist()
            num_cols = df_vis.select_dtypes(include=["int64", "float64"]).columns.tolist()
            
            col1, col2, col3 = st.columns(3)
            with col1:
                x_var = st.selectbox("ğŸ“‹ Xì¶• (ë²”ì£¼í˜•)", ["ì„ íƒ ì•ˆ í•¨"] + cat_cols)
                if x_var == "ì„ íƒ ì•ˆ í•¨": x_var = None
            with col2:
                y_var = st.selectbox("ğŸ“ˆ Yì¶• (ìˆ˜ì¹˜í˜•)", num_cols if num_cols else ["ì—†ìŒ"])
            with col3:
                graph_type = st.selectbox("ğŸ“Š ê·¸ë˜í”„ ìœ í˜•", [
                    "ë§‰ëŒ€ ê·¸ë˜í”„", "ë°•ìŠ¤ í”Œë¡¯", "ì‚°ì ë„", "íˆìŠ¤í† ê·¸ë¨", "ì„  ê·¸ë˜í”„"
                ])
            
            st.divider()
            
            if y_var and y_var != "ì—†ìŒ":
                try:
                    if graph_type == "íˆìŠ¤í† ê·¸ë¨":
                        fig = px.histogram(df_vis, x=y_var, color=x_var, title=f"{y_var} ë¶„í¬")
                    elif graph_type == "ë§‰ëŒ€ ê·¸ë˜í”„" and x_var:
                        avg_df = df_vis.groupby(x_var)[y_var].mean().reset_index()
                        fig = px.bar(avg_df, x=x_var, y=y_var, color=x_var, title=f"{x_var}ë³„ {y_var} í‰ê· ")
                    elif graph_type == "ë°•ìŠ¤ í”Œë¡¯" and x_var:
                        fig = px.box(df_vis, x=x_var, y=y_var, color=x_var, title=f"{x_var}ë³„ {y_var} ë¶„í¬")
                    elif graph_type == "ì‚°ì ë„" and x_var:
                        fig = px.scatter(df_vis, x=x_var, y=y_var, color=x_var, title=f"{x_var} vs {y_var}")
                    elif graph_type == "ì„  ê·¸ë˜í”„" and x_var:
                        line_df = df_vis.groupby(x_var)[y_var].mean().reset_index()
                        fig = px.line(line_df, x=x_var, y=y_var, markers=True, title=f"{x_var}ë³„ {y_var} ì¶”ì„¸")
                    else:
                        fig = None
                        st.info("Xì¶• ë³€ìˆ˜ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
                        
                    if fig:
                        st.plotly_chart(fig, use_container_width=True)
                except Exception as e:
                    st.error(f"ê·¸ë˜í”„ ìƒì„± ì˜¤ë¥˜: {e}")
            else:
                st.info("Yì¶• ë³€ìˆ˜ë¥¼ ì„ íƒí•˜ë©´ ê·¸ë˜í”„ê°€ í‘œì‹œë©ë‹ˆë‹¤.")

# ----------------------
#  ë‹¨ê³„ 3ï¼šë°ì´í„° ì „ì²˜ë¦¬
# ----------------------
elif st.session_state.step == 3:
    st.subheader("ğŸ§¹ ë°ì´í„° ì „ì²˜ë¦¬ & ë³€ìˆ˜ ì„ íƒ")
    
    if st.session_state.data["merged"] is None:
        st.warning("âš ï¸ ë¨¼ì € 'ë°ì´í„° ì—…ë¡œë“œ' ë‹¨ê³„ë¥¼ ì™„ë£Œí•˜ì„¸ìš”.")
    else:
        df_origin = st.session_state.data["merged"].copy()
        all_cols = df_origin.columns.tolist()

        st.markdown("### 1ï¸âƒ£ ë¶„ì„ ë³€ìˆ˜ ì„¤ì •")
        col1, col2 = st.columns(2)
        with col1:
            target_col = st.selectbox("ğŸ¯ íƒ€ê²Ÿ ë³€ìˆ˜ (Y)", options=all_cols)
        
        feature_candidates = [c for c in all_cols if c != target_col]
        
        with col2:
            default_feats = feature_candidates[:10] if len(feature_candidates) > 10 else feature_candidates
            selected_features = st.multiselect(
                "ğŸ“‹ ì…ë ¥ ë³€ìˆ˜ (X)",
                options=feature_candidates,
                default=default_feats
            )
        
        st.divider()

        if not selected_features:
            st.error("âš ï¸ ë¶„ì„í•  ë³€ìˆ˜ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
        else:
            st.session_state.preprocess["target_col"] = target_col
            tab1, tab2 = st.tabs(["âš¡ ì „ì²˜ë¦¬ ì‹¤í–‰", "ğŸ“Š ì¤‘ìš”ë„ ë¶„ì„"])
            
            with tab1:
                st.write(f"**Y(íƒ€ê²Ÿ) ê²°ì¸¡ì¹˜ ì œê±°** ë° **X(ì…ë ¥) ê²°ì¸¡ì¹˜ ì±„ìš°ê¸°**ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.")
                
                if st.button("ğŸš€ ì „ì²˜ë¦¬ ë° ì •ì œ ì‹œì‘", type="primary"):
                    with st.spinner("ë°ì´í„° ì •ì œ ì¤‘..."):
                        try:
                            clean_df = df_origin.dropna(subset=[target_col]).reset_index(drop=True)
                            dropped_count = len(df_origin) - len(clean_df)
                            if dropped_count > 0:
                                st.warning(f"âš ï¸ íƒ€ê²Ÿ ë³€ìˆ˜({target_col})ê°’ì´ ë¹„ì–´ìˆëŠ” {dropped_count}ê°œ í–‰ì„ ì œê±°í–ˆìŠµë‹ˆë‹¤.")
                            
                            X = clean_df[selected_features].copy()
                            y = clean_df[target_col].copy()
                            
                            le_target = None
                            if st.session_state.task == "logit" and y.dtype == 'object':
                                le_target = LabelEncoder()
                                y = pd.Series(le_target.fit_transform(y), index=y.index)
                                st.info("â„¹ï¸ íƒ€ê²Ÿ ë³€ìˆ˜ê°€ ë¬¸ìì—´ì´ë¼ ìë™ìœ¼ë¡œ ìˆ«ìë¡œ ë³€í™˜(Encoding)ë˜ì—ˆìŠµë‹ˆë‹¤.")
                            
                            num_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()
                            cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()
                            
                            valid_num_cols = [c for c in num_cols if X[c].notna().sum() > 0]
                            num_cols = valid_num_cols 

                            imputer = SimpleImputer(strategy='mean')
                            scaler = StandardScaler()
                            encoders = {}

                            if num_cols:
                                X_imputed = imputer.fit_transform(X[num_cols])
                                X_scaled = scaler.fit_transform(X_imputed)
                                X[num_cols] = pd.DataFrame(X_scaled, columns=num_cols, index=X.index)
                            
                            for col in cat_cols:
                                X[col] = X[col].fillna("Unknown").astype(str)
                                le = LabelEncoder()
                                trans = le.fit_transform(X[col])
                                X[col] = pd.Series(trans, index=X.index)
                                encoders[col] = le
                            
                            final_features = num_cols + cat_cols
                            X = X[final_features]
                            X = X.replace([np.inf, -np.inf], np.nan)
                            
                            if X.isna().sum().sum() > 0:
                                st.warning("âš ï¸ ì¼ë¶€ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                            
                            st.session_state.preprocess.update({
                                "feature_cols": final_features,
                                "imputer": imputer if num_cols else None,
                                "scaler": scaler if num_cols else None,
                                "encoders": encoders,
                                "num_cols": num_cols,
                                "cat_cols": cat_cols,
                                "target_encoder": le_target
                            })
                            
                            st.session_state.data["X_processed"] = X
                            st.session_state.data["y_processed"] = y
                            
                            st.success(f"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ! (ë°ì´í„° ìˆ˜: {len(X)}í–‰)")
                            st.dataframe(X.head(), width=None)
                            
                        except Exception as e:
                            st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                            
            with tab2:
                if "X_processed" in st.session_state.data and st.session_state.data["X_processed"] is not None:
                    if st.button("ğŸ” ë³€ìˆ˜ ì¤‘ìš”ë„ í™•ì¸"):
                        X_p = st.session_state.data["X_processed"]
                        y_p = st.session_state.data["y_processed"]
                        
                        try:
                            if st.session_state.task == "logit":
                                model = DecisionTreeClassifier(max_depth=5, random_state=42)
                            else:
                                model = DecisionTreeRegressor(max_depth=5, random_state=42)
                            
                            model.fit(X_p, y_p)
                            
                            imp = pd.DataFrame({
                                "Feature": X_p.columns,
                                "Importance": model.feature_importances_
                            }).sort_values("Importance", ascending=False)
                            
                            st.plotly_chart(
                                px.bar(imp, x="Importance", y="Feature", orientation='h', title="ë³€ìˆ˜ ì¤‘ìš”ë„"),
                                use_container_width=True
                            )
                        except Exception as e:
                            st.error(f"ë¶„ì„ ì‹¤íŒ¨: {e}")
                else:
                    st.info("ğŸ‘ˆ ë¨¼ì € [ì „ì²˜ë¦¬ ì‹¤í–‰] ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")

# ----------------------
#  ë‹¨ê³„ 4ï¼šëª¨ë¸ í•™ìŠµ
# ----------------------
elif st.session_state.step == 4:
    st.subheader("ğŸš€ í•˜ì´ë¸Œë¦¬ë“œëª¨í˜• í•™ìŠµ")
    
    if "X_processed" not in st.session_state.data or st.session_state.data["X_processed"] is None:
        st.warning("âš ï¸ ë¨¼ì €ã€Œë°ì´í„° ì „ì²˜ë¦¬ã€ë‹¨ê³„ë¥¼ ì™„ë£Œí•˜ì„¸ìš”")
    else:
        X = st.session_state.data["X_processed"]
        y = st.session_state.data["y_processed"]
        
        st.markdown("### 1. í•™ìŠµ ì„¤ì • í™•ì¸")
        target_unique_count = y.nunique()
        
        if target_unique_count < 2:
            st.error(f"âŒ íƒ€ê²Ÿ ë³€ìˆ˜(Y)ì˜ ê°’ ì¢…ë¥˜ê°€ 1ê°œ({y.unique()[0]})ë¿ì…ë‹ˆë‹¤.")
            st.stop()
            
        col1, col2 = st.columns(2)
        with col1:
            test_size = st.slider("í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¹„ìœ¨ (Test Size)", 0.1, 0.4, 0.2, 0.05)
        with col2:
            st.info(f"í˜„ì¬ ë¶„ì„ ëª¨ë“œ: **{st.session_state.task}**")

        stratify_param = None
        if st.session_state.task == "logit":
            class_counts = y.value_counts()
            if (class_counts >= 2).all():
                stratify_param = y
            else:
                st.warning(f"âš ï¸ ì¸µí™” ì¶”ì¶œ ë¯¸ì ìš©: ë°ì´í„° ë¶€ì¡± í´ë˜ìŠ¤ ì¡´ì¬")
        
        try:
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=test_size, random_state=42, stratify=stratify_param
            )
        except ValueError:
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=test_size, random_state=42, stratify=None
            )

        st.divider()
        st.markdown("### 2. í•˜ì´ë¸Œë¦¬ë“œ ê°€ì¤‘ì¹˜ ì„¤ì •")
        w_col1, w_col2 = st.columns(2)
        with w_col1:
            reg_weight = st.slider("íšŒê·€ ëª¨ë¸ ë¹„ì¤‘", 0.0, 1.0, 0.5, key="reg_weight_slider")
        with w_col2:
            st.metric("íŠ¸ë¦¬ ëª¨ë¸ ë¹„ì¤‘", f"{1.0 - reg_weight:.1f}")
            
        if st.button("ğŸš€ ëª¨ë¸ í•™ìŠµ ì‹œì‘", type="primary"):
            with st.spinner("ëª¨ë¸ í•™ìŠµ ì¤‘ì…ë‹ˆë‹¤..."):
                try:
                    if st.session_state.task == "logit":
                        reg_model = LogisticRegression(max_iter=2000) 
                        dt_model = DecisionTreeClassifier(random_state=42, max_depth=10)
                    else:
                        reg_model = LinearRegression()
                        dt_model = DecisionTreeRegressor(random_state=42, max_depth=10)

                    reg_model.fit(X_train, y_train)
                    dt_model.fit(X_train, y_train)
                    
                    st.session_state.models["regression"] = reg_model
                    st.session_state.models["decision_tree"] = dt_model
                    st.session_state.models["mixed_weights"] = {
                        "regression": reg_weight, "decision_tree": 1.0 - reg_weight
                    }
                    
                    st.session_state.data.update({
                        "X_train": X_train, "X_test": X_test, 
                        "y_train": y_train, "y_test": y_test
                    })
                    
                    st.success("âœ… ëª¨ë¸ í•™ìŠµì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                    st.write(f"í•™ìŠµ ë°ì´í„°: {len(X_train)}ê±´ / í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(X_test)}ê±´")
                        
                except Exception as e:
                    st.error(f"âŒ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")

# ----------------------
#  ë‹¨ê³„ 5ï¼šëª¨ë¸ ì˜ˆì¸¡
# ----------------------
elif st.session_state.step == 5:
    st.subheader("ğŸ¯ ëª¨ë¸ ì˜ˆì¸¡")
    
    if st.session_state.models["regression"] is None:
        st.warning("ë¨¼ì €ã€Œëª¨ë¸ í•™ìŠµã€ë‹¨ê³„ë¥¼ ì™„ë£Œí•˜ì„¸ìš”")
    else:
        def predict_pipeline(input_df):
            preprocess = st.session_state.preprocess
            X = input_df.copy()
            
            num_cols = preprocess["num_cols"]
            cat_cols = preprocess["cat_cols"]
            
            # ìˆ˜ì¹˜í˜• ì²˜ë¦¬
            if preprocess["imputer"]:
                # ì…ë ¥ëœ ì»¬ëŸ¼ì´ feature_colsì— ìˆëŠ”ì§€ í™•ì¸
                existing_nums = [c for c in num_cols if c in X.columns]
                if existing_nums:
                    X[existing_nums] = preprocess["imputer"].transform(X[existing_nums])
                    X[existing_nums] = preprocess["scaler"].transform(X[existing_nums])
            
            # ë²”ì£¼í˜• ì²˜ë¦¬
            for col in cat_cols:
                if col in X.columns:
                    X[col] = X[col].fillna("Unknown").astype(str)
                    encoder = preprocess["encoders"].get(col)
                    if encoder:
                        known_classes = set(encoder.classes_)
                        # ì•Œë ¤ì§€ì§€ ì•Šì€ í´ë˜ìŠ¤ëŠ” 0ìœ¼ë¡œ ì²˜ë¦¬ (LabelEncoder í•œê³„)
                        X[col] = X[col].apply(lambda x: encoder.transform([x])[0] if x in known_classes else 0)

            # ì»¬ëŸ¼ ë§ì¶”ê¸°
            for c in preprocess["feature_cols"]:
                if c not in X.columns:
                    X[c] = 0
            X = X[preprocess["feature_cols"]]
            
            reg_model = st.session_state.models["regression"]
            dt_model = st.session_state.models["decision_tree"]
            weights = st.session_state.models["mixed_weights"]
            
            if st.session_state.task == "logit":
                reg_p = reg_model.predict_proba(X)[:, 1]
                dt_p = dt_model.predict_proba(X)[:, 1]
                mixed_p = weights["regression"] * reg_p + weights["decision_tree"] * dt_p
                pred = (mixed_p >= 0.5).astype(int)
                return pred, mixed_p
            else:
                reg_p = reg_model.predict(X)
                dt_p = dt_model.predict(X)
                mixed_p = weights["regression"] * reg_p + weights["decision_tree"] * dt_p
                return mixed_p, None

        mode = st.radio("ì˜ˆì¸¡ ë°©ì‹", ["ë‹¨ì¼ ë°ì´í„° ì…ë ¥", "ì¼ê´„ ì—…ë¡œë“œ (CSV)"])
        
        if mode == "ë‹¨ì¼ ë°ì´í„° ì…ë ¥":
            st.markdown("#### ë°ì´í„° ì…ë ¥")
            original_features = [c for c in st.session_state.data["merged"].columns 
                               if c not in [st.session_state.preprocess["target_col"]]]
            
            input_data = {}
            with st.form("pred_form"):
                cols = st.columns(3)
                for i, col in enumerate(original_features[:9]):
                    with cols[i % 3]:
                        if col in st.session_state.data["merged"].columns:
                            col_type = st.session_state.data["merged"][col].dtype
                            if pd.api.types.is_numeric_dtype(col_type):
                                input_data[col] = st.number_input(col, value=0.0)
                            else:
                                opts = st.session_state.data["merged"][col].astype(str).unique()
                                input_data[col] = st.selectbox(col, options=opts)
                submit = st.form_submit_button("ì˜ˆì¸¡í•˜ê¸°")
            
            if submit:
                input_df = pd.DataFrame([input_data])
                try:
                    pred, proba = predict_pipeline(input_df)
                    st.divider()
                    if st.session_state.task == "logit":
                        st.metric("ì˜ˆì¸¡ ê²°ê³¼", "ì–‘ì„±(Positive)" if pred[0]==1 else "ìŒì„±(Negative)")
                        st.metric("í™•ë¥ ", f"{proba[0]:.2%}")
                    else:
                        st.metric("ì˜ˆì¸¡ ê°’", f"{pred[0]:.4f}")
                except Exception as e:
                    st.error(f"ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜: {e}")
                    
        else:
            up_file = st.file_uploader("CSV ì—…ë¡œë“œ", type=["csv"])
            if up_file:
                batch_df = pd.read_csv(up_file)
                if st.button("ì¼ê´„ ì˜ˆì¸¡ ì‹œì‘"):
                    try:
                        pred, proba = predict_pipeline(batch_df)
                        batch_df["Predicted"] = pred
                        if proba is not None:
                            batch_df["Probability"] = proba
                        st.dataframe(batch_df.head())
                        st.download_button("ê²°ê³¼ ë‹¤ìš´ë¡œë“œ", batch_df.to_csv().encode('utf-8'), "prediction.csv")
                    except Exception as e:
                        st.error(f"ì˜ˆì¸¡ ì˜¤ë¥˜: {e}")

# ----------------------
#  ë‹¨ê³„ 6ï¼šì„±ëŠ¥ í‰ê°€
# ----------------------
elif st.session_state.step == 6:
    st.subheader("ğŸ“ˆ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€")
    
    if st.session_state.models["regression"] is None:
        st.warning("ë¨¼ì €ã€Œëª¨ë¸ í•™ìŠµã€ë‹¨ê³„ë¥¼ ì™„ë£Œí•˜ì„¸ìš”")
    else:
        X_test = st.session_state.data["X_test"]
        y_test = st.session_state.data["y_test"]
        
        reg_model = st.session_state.models["regression"]
        dt_model = st.session_state.models["decision_tree"]
        weights = st.session_state.models["mixed_weights"]
        
        if st.session_state.task == "logit":
            reg_p = reg_model.predict_proba(X_test)[:, 1]
            dt_p = dt_model.predict_proba(X_test)[:, 1]
            mixed_p = weights["regression"] * reg_p + weights["decision_tree"] * dt_p
            
            reg_pred = reg_model.predict(X_test)
            dt_pred = dt_model.predict(X_test)
            mixed_pred = (mixed_p >= 0.5).astype(int)
            
            def get_metrics(y, pred, proba):
                return {
                    "ACC": accuracy_score(y, pred),
                    "AUC": auc(*roc_curve(y, proba)[:2])
                }
            
            m1 = get_metrics(y_test, reg_pred, reg_p)
            m2 = get_metrics(y_test, dt_pred, dt_p)
            m3 = get_metrics(y_test, mixed_pred, mixed_p)
            
            metrics = pd.DataFrame([m1, m2, m3], index=["íšŒê·€ë¶„ì„", "ì˜ì‚¬ê²°ì •ë‚˜ë¬´", "í•˜ì´ë¸Œë¦¬ë“œ"])
            st.table(metrics)
            
            fpr, tpr, _ = roc_curve(y_test, mixed_p)
            fig = px.area(x=fpr, y=tpr, title=f"ROC Curve (Hybrid AUC={m3['AUC']:.3f})", 
                        labels=dict(x="False Positive Rate", y="True Positive Rate"))
            fig.add_shape(type='line', line=dict(dash='dash'), x0=0, x1=1, y0=0, y1=1)
            st.plotly_chart(fig, use_container_width=True)
            
        else:
            reg_pred = reg_model.predict(X_test)
            dt_pred = dt_model.predict(X_test)
            mixed_pred = weights["regression"] * reg_pred + weights["decision_tree"] * dt_pred
            
            def get_reg_metrics(y, pred):
                return {
                    "MAE": mean_absolute_error(y, pred),
                    "RMSE": np.sqrt(mean_squared_error(y, pred)),
                    "R2": r2_score(y, pred)
                }
            
            m1 = get_reg_metrics(y_test, reg_pred)
            m2 = get_reg_metrics(y_test, dt_pred)
            m3 = get_reg_metrics(y_test, mixed_pred)
            
            metrics = pd.DataFrame([m1, m2, m3], index=["ì„ í˜•íšŒê·€", "ì˜ì‚¬ê²°ì •ë‚˜ë¬´", "í•˜ì´ë¸Œë¦¬ë“œ"])
            st.table(metrics)
            
            fig = px.scatter(x=y_test, y=mixed_pred, title="ì‹¤ì œê°’ vs ì˜ˆì¸¡ê°’ (Hybrid)", 
                           labels={"x": "ì‹¤ì œê°’", "y": "ì˜ˆì¸¡ê°’"})
            fig.add_shape(type='line', line=dict(dash='dash', color='red'), 
                        x0=y_test.min(), x1=y_test.max(), y0=y_test.min(), y1=y_test.max())
            st.plotly_chart(fig, use_container_width=True)
            
        if hasattr(dt_model, "feature_importances_"):
            st.markdown("### ğŸŒ³ ë³€ìˆ˜ ì¤‘ìš”ë„ (ì˜ì‚¬ê²°ì •ë‚˜ë¬´ ê¸°ì¤€)")
            imp_df = pd.DataFrame({
                "Feature": st.session_state.preprocess["feature_cols"],
                "Importance": dt_model.feature_importances_
            }).sort_values("Importance", ascending=False).head(10)
            
            fig_imp = px.bar(imp_df, x="Importance", y="Feature", orientation='h', title="Top 10 Feature Importance")
            st.plotly_chart(fig_imp, use_container_width=True)
