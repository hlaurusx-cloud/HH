import streamlit as st
import pandas as pd
import numpy as np
import os
import joblib
import plotly.express as px
import plotly.graph_objects as go
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder
from sklearn.impute import SimpleImputer
from sklearn.linear_model import LinearRegression, LogisticRegression
from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor
from sklearn.metrics import (
    accuracy_score, auc, roc_curve, confusion_matrix,
    mean_absolute_error, mean_squared_error, r2_score
)
import warnings
warnings.filterwarnings("ignore")

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="í•˜ì´ë¸Œë¦¬ë“œëª¨í˜• í”„ë ˆì„ì›Œí¬", layout="wide")

# ----------------------
# 1. í˜ì´ì§€ ê¸°ë³¸ ì„¤ì •
# ----------------------
st.set_page_config(
    page_title="í•˜ì´ë¸Œë¦¬ë“œëª¨í˜• ë™ì  í”„ë ˆì„ì›Œí¬ï¼ˆì˜ì‚¬ê²°ì •ë‚˜ë¬´+íšŒê·€ë¶„ì„ï¼‰",
    page_icon="ğŸ“Š",
    layout="wide"
)

# ì „ì—­ ìƒíƒœ ê´€ë¦¬ï¼ˆê° ë‹¨ê³„ ë°ì´í„°/ëª¨ë¸ ì €ì¥ï¼Œìƒˆë¡œê³ ì¹¨ ì‹œ ì†ì‹¤ ë°©ì§€ï¼‰
if "step" not in st.session_state:
    st.session_state.step = 0  # 0:ì´ˆê¸°í™”ë©´ 1:ë°ì´í„°ì—…ë¡œë“œ 2:ë°ì´í„°ì‹œê°í™” 3:ë°ì´í„°ì „ì²˜ë¦¬ 4:ëª¨ë¸í•™ìŠµ 5:ì˜ˆì¸¡ 6:í‰ê°€
if "data" not in st.session_state:
    st.session_state.data = {"merged": None}  # ë‹¨ì¼ íŒŒì¼ë§Œ ì €ì¥
if "preprocess" not in st.session_state:
    st.session_state.preprocess = {"imputer": None, "scaler": None, "encoders": None, "feature_cols": None, "target_col": None}
if "models" not in st.session_state:
    # æ¨¡å‹ï¼šregressionï¼ˆíšŒê·€ë¶„ì„ï¼‰ã€decision_treeï¼ˆì˜ì‚¬ê²°ì •ë‚˜ë¬´ï¼‰
    st.session_state.models = {"regression": None, "decision_tree": None, "mixed_weights": {"regression": 0.3, "decision_tree": 0.7}}
if "task" not in st.session_state:
    st.session_state.task = "logit"  # ê¸°ë³¸ê°’ logitï¼ˆë¶„ë¥˜ï¼‰ï¼Œì˜ì‚¬ê²°ì •ë‚˜ë¬´ï¼ˆíšŒê·€ï¼‰ë¡œ ì „í™˜ ê°€ëŠ¥

# ----------------------
# 2. ì‚¬ì´ë“œë°”ï¼šë‹¨ê³„å¯¼èˆª + í•µì‹¬ ì„¤ì •
# ----------------------
st.sidebar.title("ğŸ“Œ í•˜ì´ë¸Œë¦¬ë“œëª¨í˜• ì‘ì—… íë¦„")
st.sidebar.divider()

# ë‹¨ê³„å¯¼èˆª ë²„íŠ¼ï¼ˆæ–°å¢ã€Œë°ì´í„° ì‹œê°í™”ã€ë‹¨ê³„ï¼‰
steps = ["ì´ˆê¸° ì„¤ì •", "ë°ì´í„° ì—…ë¡œë“œ", "ë°ì´í„° ì‹œê°í™”", "ë°ì´í„° ì „ì²˜ë¦¬", "ëª¨ë¸ í•™ìŠµ", "ëª¨ë¸ ì˜ˆì¸¡", "ì„±ëŠ¥ í‰ê°€"]
for i, step_name in enumerate(steps):
    if st.sidebar.button(step_name, key=f"btn_{i}"):
        st.session_state.step = i

# í•µì‹¬ ì„¤ì •ï¼ˆì‘ì—… ìœ í˜• + í˜¼í•© ê°€ì¤‘ì¹˜ï¼‰
st.sidebar.divider()
st.sidebar.subheader("í•µì‹¬ ì„¤ì •")
st.session_state.task = st.sidebar.radio("ì‘ì—… ìœ í˜•", options=["logit", "ì˜ì‚¬ê²°ì •ë‚˜ë¬´"], index=0)

if st.session_state.step >= 4:  # ëª¨ë¸ í•™ìŠµ í›„ ê°€ì¤‘ì¹˜ ì¡°ì • ê°€ëŠ¥
    st.sidebar.subheader("í•˜ì´ë¸Œë¦¬ë“œëª¨í˜• ê°€ì¤‘ì¹˜")
    reg_weight = st.sidebar.slider(
        "íšŒê·€ ë¶„ì„ ê°€ì¤‘ì¹˜ï¼ˆí•´ì„ë ¥ ê°•í•¨ï¼‰",
        min_value=0.0, max_value=1.0, value=st.session_state.models["mixed_weights"]["regression"], step=0.1
    )
    st.session_state.models["mixed_weights"]["regression"] = reg_weight
    st.session_state.models["mixed_weights"]["decision_tree"] = 1 - reg_weight
    st.sidebar.text(f"ì˜ì‚¬ê²°ì •ë‚˜ë¬´ ê°€ì¤‘ì¹˜ï¼ˆì •í™•ë„ ë†’ìŒï¼‰ï¼š{1 - reg_weight:.1f}")

# ----------------------
# 3. ë©”ì¸ í˜ì´ì§€ï¼šë‹¨ê³„ë³„ ë‚´ìš© í‘œì‹œ
# ----------------------
st.title("ğŸ“Š í•˜ì´ë¸Œë¦¬ë“œëª¨í˜• ë™ì  ë°°í¬ í”„ë ˆì„ì›Œí¬")
st.markdown("**ë‹¨ì¼ ì›ë³¸ ë°ì´í„° íŒŒì¼ ì—…ë¡œë“œ í›„ï¼Œì‹œê°í™”â†’ì „ì²˜ë¦¬â†’í•™ìŠµâ†’ì˜ˆì¸¡ ì „ê³¼ì •ì„ í•œ ë²ˆì— ì™„ì„±**")
st.markdown("### ğŸ§© í•µì‹¬ ëª¨ë¸ï¼šíšŒê·€ ë¶„ì„ï¼ˆRegressionï¼‰+ ì˜ì‚¬ê²°ì •ë‚˜ë¬´ï¼ˆDecision Treeï¼‰")
st.divider()

# ==============================================================================
# ë©”ì¸ ë¡œì§ ì‹œì‘
# ==============================================================================

# ----------------------
#  ë‹¨ê³„ 0ï¼šì´ˆê¸° ì„¤ì •ï¼ˆì•ˆë‚´ í˜ì´ì§€ï¼‰
# ----------------------
if st.session_state.step == 0:
    st.subheader("ğŸ‰ í•˜ì´ë¸Œë¦¬ë“œëª¨í˜• ë™ì  í”„ë ˆì„ì›Œí¬ì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤")
    st.markdown("""
    ë³¸ í”„ë ˆì„ì›Œí¬ëŠ” **ë°ì´í„° ìˆ˜ë ¹ í›„ ì§ì ‘ ì—…ë¡œë“œí•˜ì—¬ ì‚¬ìš©**í•  ìˆ˜ ìˆìœ¼ë©°ï¼Œì‚¬ì „ ì „ì²˜ë¦¬ë‚˜ ëª¨ë¸ í•™ìŠµì´ í•„ìš” ì—†ìŠµë‹ˆë‹¤. í•µì‹¬ íë¦„ì€ ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤ï¼š
    
    1. **ë°ì´í„° ì—…ë¡œë“œ**ï¼šë‹¨ì¼ ì›ë³¸ íŒŒì¼ï¼ˆCSV/Parquet/Excelï¼‰ì„ ì—…ë¡œë“œ
    2. **ë°ì´í„° ì‹œê°í™”**ï¼šë²”ì£¼í˜• ë³€ìˆ˜ì™€ ìˆ˜ì¹˜í˜• ë³€ìˆ˜ë¥¼ ì„ íƒí•˜ì—¬ ë‹¤ì–‘í•œ ê·¸ë˜í”„ë¡œ ë°ì´í„° íƒìƒ‰
    3. **ë°ì´í„° ì „ì²˜ë¦¬**ï¼šê²°ì¸¡ê°’ ì±„ìš°ê¸°ã€ë²”ì£¼í˜• íŠ¹ì§• ì¸ì½”ë”©
    4. **ëª¨ë¸ í•™ìŠµ**ï¼šã€ŒíšŒê·€ ë¶„ì„+ì˜ì‚¬ê²°ì •ë‚˜ë¬´ã€í•˜ì´ë¸Œë¦¬ë“œëª¨í˜• í•™ìŠµ
    5. **ëª¨ë¸ ì˜ˆì¸¡**ï¼šë‹¨ì¼ ë°ì´í„° ì…ë ¥ ë˜ëŠ” ì¼ê´„ ì—…ë¡œë“œ ì˜ˆì¸¡ì„ ì§€ì›
    6. **ì„±ëŠ¥ í‰ê°€**ï¼ší•˜ì´ë¸Œë¦¬ë“œëª¨í˜•ê³¼ ë‹¨ì¼ ëª¨í˜•ì˜ ì„±ëŠ¥ì„ ë¹„êµ
    
    ### ì ìš© ê°€ëŠ¥ í™˜ê²½
    - logit ì‘ì—…ï¼ˆë¶„ë¥˜ï¼‰ï¼šì‚¬ìš©ìê°€ ì„œë¹„ìŠ¤ë¥¼ ìˆ˜ë½í• ì§€ ì—¬ë¶€ã€ìœ„ë°˜ ì—¬ë¶€ç­‰ ì´ì§„ ì˜ˆì¸¡ï¼ˆëª¨ë¸ï¼šë¡œì§€ìŠ¤í‹± íšŒê·€+ë¶„ë¥˜ ì˜ì‚¬ê²°ì •ë‚˜ë¬´ï¼‰
    - ì˜ì‚¬ê²°ì •ë‚˜ë¬´ ì‘ì—…ï¼ˆíšŒê·€ï¼‰ï¼šíŒë§¤ëŸ‰ã€ê¸ˆì•¡ã€í‰ì ç­‰ ì—°ì†ê°’ ì˜ˆì¸¡ï¼ˆëª¨ë¸ï¼šì„ í˜• íšŒê·€+íšŒê·€ ì˜ì‚¬ê²°ì •ë‚˜ë¬´ï¼‰
    
    ### ì™¼ìª½ ì‚¬ì´ë“œë°”ì—ì„œ **ã€Œ1. ë°ì´í„° ì—…ë¡œë“œã€**ë¥¼ ì„ íƒí•˜ì—¬ ì‹œì‘í•˜ì„¸ìš”!
    """)

# ----------------------
#  ë‹¨ê³„ 1ï¼šë°ì´í„° ì—…ë¡œë“œ (ì¸ì½”ë”© ìë™ í•´ê²° ë²„ì „)
# ----------------------
elif st.session_state.step == 1:
    st.subheader("ğŸ“¤ ë°ì´í„° ì—…ë¡œë“œ")
    
    tab1, tab2 = st.tabs(["ğŸ“‚ ë‚´ íŒŒì¼ ì—…ë¡œë“œ", "ğŸ’¾ ì„œë²„ ê¸°ë³¸ ë°ì´í„° ì‚¬ìš©"])
    
    # ì¸ì½”ë”© ì²˜ë¦¬ë¥¼ ìœ„í•œ ë‚´ë¶€ í•¨ìˆ˜
    def load_csv_safe(file_buffer):
        # ì‹œë„í•  ì¸ì½”ë”© ëª©ë¡ (ìˆœì„œëŒ€ë¡œ ì‹œë„)
        encodings = ['utf-8', 'cp949', 'euc-kr', 'utf-8-sig', 'latin1']
        
        for enc in encodings:
            try:
                file_buffer.seek(0) # íŒŒì¼ í¬ì¸í„° ì´ˆê¸°í™”
                df = pd.read_csv(file_buffer, encoding=enc)
                return df, enc # ì„±ê³µí•˜ë©´ ë°ì´í„°ì™€ ì¸ì½”ë”© ë°˜í™˜
            except UnicodeDecodeError:
                continue # ì‹¤íŒ¨í•˜ë©´ ë‹¤ìŒ ì¸ì½”ë”© ì‹œë„
            except Exception as e:
                return None, str(e) # ê¸°íƒ€ ì—ëŸ¬
        return None, "ëª¨ë“  ì¸ì½”ë”© ì‹œë„ ì‹¤íŒ¨"

    with tab1:
        st.markdown("ì§€ì› í˜•ì‹ï¼šCSVã€Parquetã€Excelï¼ˆ.xlsx/.xlsï¼‰")
        uploaded_file = st.file_uploader("ë°ì´í„° íŒŒì¼ ì„ íƒ", type=["csv", "parquet", "xlsx", "xls"], key="single_file")
        
        if uploaded_file:
            try:
                df = None
                # í™•ì¥ìë³„ ë¡œë“œ
                if uploaded_file.name.endswith('.csv'):
                    df, enc_used = load_csv_safe(uploaded_file)
                    if df is None:
                        st.error(f"âŒ CSV íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {enc_used}")
                    else:
                        st.caption(f"â„¹ï¸ ê°ì§€ëœ ì¸ì½”ë”©: {enc_used}")
                        
                elif uploaded_file.name.endswith('.parquet'):
                    df = pd.read_parquet(uploaded_file)
                else:
                    df = pd.read_excel(uploaded_file)
                
                if df is not None:
                    # ì¸ë±ìŠ¤ ì´ˆê¸°í™” (ì „ì²˜ë¦¬ ì—ëŸ¬ ë°©ì§€ìš© í•„ìˆ˜)
                    df = df.reset_index(drop=True)
                    st.session_state.data["merged"] = df
                    st.success(f"âœ… íŒŒì¼ ì—…ë¡œë“œ ì„±ê³µ! ({len(df):,} í–‰)")
                
            except Exception as e:
                st.error(f"âŒ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    with tab2:
        DEFAULT_FILE_PATH = "combined_loan_data.csv" 
        st.info(f"ğŸ’¡ **ê¸°ë³¸ ë°ì´í„° ì„¤ëª…**: ëŒ€ì¶œ ê´€ë ¨ í†µí•© ë°ì´í„° (`{DEFAULT_FILE_PATH}`)")
        
        if st.button("ê¸°ë³¸ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°", type="primary"):
            if os.path.exists(DEFAULT_FILE_PATH):
                # ê¸°ë³¸ íŒŒì¼ë„ ì•ˆì „í•˜ê²Œ ë¡œë“œ ì‹œë„
                with open(DEFAULT_FILE_PATH, 'rb') as f:
                    df_default, enc_used = load_csv_safe(f)
                
                if df_default is not None:
                    st.session_state.data["merged"] = df_default.reset_index(drop=True)
                    st.success(f"âœ… ê¸°ë³¸ ë°ì´í„° ë¡œë“œ ì„±ê³µ! ({len(df_default):,} í–‰, ì¸ì½”ë”©: {enc_used})")
                    st.rerun()
                else:
                    st.error("âŒ ê¸°ë³¸ íŒŒì¼ì„ ì½ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (ì¸ì½”ë”© ì˜¤ë¥˜).")
            else:
                st.error(f"âš ï¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {DEFAULT_FILE_PATH}")

    # ë°ì´í„° ë¯¸ë¦¬ë³´ê¸°
    if st.session_state.data.get("merged") is not None:
        df_merged = st.session_state.data["merged"]
        st.divider()
        st.markdown(f"### âœ… í˜„ì¬ ë¡œë“œëœ ë°ì´í„° ({len(df_merged):,} í–‰)")
        st.dataframe(df_merged.head(5), width='stretch')

# ----------------------
#  ë‹¨ê³„ 2ï¼šë°ì´í„° ì‹œê°í™” (ìˆ˜ì •ë¨)
# ----------------------
elif st.session_state.step == 2:
    st.subheader("ğŸ“Š ë°ì´í„° ì‹œê°í™”")
    
    if st.session_state.data["merged"] is None:
        st.warning("âš ï¸ ë¨¼ì € 'ë°ì´í„° ì—…ë¡œë“œ' ë‹¨ê³„ë¥¼ ì™„ë£Œí•˜ì„¸ìš”")
    else:
        df = st.session_state.data["merged"]
        
        # --- ë³€ìˆ˜ ì„ íƒ (Variable Selection) ---
        st.markdown("### 1ï¸âƒ£ ì‹œê°í™”í•  ë³€ìˆ˜ ì„ íƒ")
        all_cols = df.columns.tolist()
        default_selection = all_cols[:10] if len(all_cols) > 10 else all_cols
        
        selected_cols = st.multiselect(
            "ë¶„ì„ ëŒ€ìƒ ë³€ìˆ˜ ì„ íƒ",
            options=all_cols,
            default=default_selection
        )
        
        if not selected_cols:
            st.error("âš ï¸ ìµœì†Œ í•˜ë‚˜ ì´ìƒì˜ ë³€ìˆ˜ë¥¼ ì„ íƒí•´ì•¼ ì‹œê°í™”ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.")
        else:
            df_vis = df[selected_cols]
            st.divider()
            
            # --- ê·¸ë˜í”„ ì„¤ì • ---
            st.markdown("### 2ï¸âƒ£ ê·¸ë˜í”„ ì„¤ì •")
            cat_cols = df_vis.select_dtypes(include=["object", "category"]).columns.tolist()
            num_cols = df_vis.select_dtypes(include=["int64", "float64"]).columns.tolist()
            
            col1, col2, col3 = st.columns(3)
            with col1:
                x_var = st.selectbox("ğŸ“‹ Xì¶• (ë²”ì£¼í˜•)", ["ì„ íƒ ì•ˆ í•¨"] + cat_cols)
                if x_var == "ì„ íƒ ì•ˆ í•¨": x_var = None
            with col2:
                y_var = st.selectbox("ğŸ“ˆ Yì¶• (ìˆ˜ì¹˜í˜•)", num_cols if num_cols else ["ì—†ìŒ"])
            with col3:
                graph_type = st.selectbox("ğŸ“Š ê·¸ë˜í”„ ìœ í˜•", [
                    "ë§‰ëŒ€ ê·¸ë˜í”„", "ë°•ìŠ¤ í”Œë¡¯", "ì‚°ì ë„", "íˆìŠ¤í† ê·¸ë¨", "ì„  ê·¸ë˜í”„"
                ])
            
            st.divider()
            
            # ì‹œê°í™” ì¶œë ¥
            if y_var and y_var != "ì—†ìŒ":
                try:
                    if graph_type == "íˆìŠ¤í† ê·¸ë¨":
                        fig = px.histogram(df_vis, x=y_var, color=x_var, title=f"{y_var} ë¶„í¬")
                    elif graph_type == "ë§‰ëŒ€ ê·¸ë˜í”„" and x_var:
                        avg_df = df_vis.groupby(x_var)[y_var].mean().reset_index()
                        fig = px.bar(avg_df, x=x_var, y=y_var, color=x_var, title=f"{x_var}ë³„ {y_var} í‰ê· ")
                    elif graph_type == "ë°•ìŠ¤ í”Œë¡¯" and x_var:
                        fig = px.box(df_vis, x=x_var, y=y_var, color=x_var, title=f"{x_var}ë³„ {y_var} ë¶„í¬")
                    elif graph_type == "ì‚°ì ë„" and x_var:
                        fig = px.scatter(df_vis, x=x_var, y=y_var, color=x_var, title=f"{x_var} vs {y_var}")
                    elif graph_type == "ì„  ê·¸ë˜í”„" and x_var:
                        line_df = df_vis.groupby(x_var)[y_var].mean().reset_index()
                        fig = px.line(line_df, x=x_var, y=y_var, markers=True, title=f"{x_var}ë³„ {y_var} ì¶”ì„¸")
                    else:
                        fig = None
                        st.info("Xì¶• ë³€ìˆ˜ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
                        
                    if fig:
                        st.plotly_chart(fig, width='stretch')
                except Exception as e:
                    st.error(f"ê·¸ë˜í”„ ìƒì„± ì˜¤ë¥˜: {e}")
            else:
                st.info("Yì¶• ë³€ìˆ˜ë¥¼ ì„ íƒí•˜ë©´ ê·¸ë˜í”„ê°€ í‘œì‹œë©ë‹ˆë‹¤.")

# ----------------------
#  ë‹¨ê³„ 3ï¼šë°ì´í„° ì „ì²˜ë¦¬ (ì™„ì „ ìˆ˜ì •: íƒ€ê²Ÿ ê²°ì¸¡ì¹˜ ì œê±° ë° ìë™ ì¸ì½”ë”©)
# ----------------------
elif st.session_state.step == 3:
    st.subheader("ğŸ§¹ ë°ì´í„° ì „ì²˜ë¦¬ & ë³€ìˆ˜ ì„ íƒ (Final Fix)")
    
    if st.session_state.data["merged"] is None:
        st.warning("âš ï¸ ë¨¼ì € 'ë°ì´í„° ì—…ë¡œë“œ' ë‹¨ê³„ë¥¼ ì™„ë£Œí•˜ì„¸ìš”.")
    else:
        # ì›ë³¸ ë°ì´í„° ë¡œë“œ
        df_origin = st.session_state.data["merged"].copy()
        all_cols = df_origin.columns.tolist()

        st.markdown("### 1ï¸âƒ£ ë¶„ì„ ë³€ìˆ˜ ì„¤ì •")
        
        col1, col2 = st.columns(2)
        with col1:
            target_col = st.selectbox("ğŸ¯ íƒ€ê²Ÿ ë³€ìˆ˜ (Y)", options=all_cols)
        
        feature_candidates = [c for c in all_cols if c != target_col]
        
        with col2:
            default_feats = feature_candidates[:10] if len(feature_candidates) > 10 else feature_candidates
            selected_features = st.multiselect(
                "ğŸ“‹ ì…ë ¥ ë³€ìˆ˜ (X)",
                options=feature_candidates,
                default=default_feats
            )
        
        st.divider()

        if not selected_features:
            st.error("âš ï¸ ë¶„ì„í•  ë³€ìˆ˜ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")
        else:
            # ì„¤ì • ì €ì¥
            st.session_state.preprocess["target_col"] = target_col
            
            tab1, tab2 = st.tabs(["âš¡ ì „ì²˜ë¦¬ ì‹¤í–‰", "ğŸ“Š ì¤‘ìš”ë„ ë¶„ì„"])
            
            with tab1:
                st.write(f"**Y(íƒ€ê²Ÿ) ê²°ì¸¡ì¹˜ ì œê±°** ë° **X(ì…ë ¥) ê²°ì¸¡ì¹˜ ì±„ìš°ê¸°**ë¥¼ ìˆ˜í–‰í•©ë‹ˆë‹¤.")
                
                if st.button("ğŸš€ ì „ì²˜ë¦¬ ë° ì •ì œ ì‹œì‘", type="primary"):
                    with st.spinner("ë°ì´í„° ì •ì œ ì¤‘..."):
                        try:
                            # [í•µì‹¬ 1] íƒ€ê²Ÿ(Y)ì´ ë¹„ì–´ìˆëŠ” í–‰ ì œê±° (ì´ê²Œ ì—†ìœ¼ë©´ NaN ì—ëŸ¬ ë°œìƒ)
                            clean_df = df_origin.dropna(subset=[target_col]).reset_index(drop=True)
                            
                            dropped_count = len(df_origin) - len(clean_df)
                            if dropped_count > 0:
                                st.warning(f"âš ï¸ íƒ€ê²Ÿ ë³€ìˆ˜({target_col})ê°’ì´ ë¹„ì–´ìˆëŠ” {dropped_count}ê°œ í–‰ì„ ì œê±°í–ˆìŠµë‹ˆë‹¤.")
                            
                            # X, y ë¶„ë¦¬
                            X = clean_df[selected_features].copy()
                            y = clean_df[target_col].copy()
                            
                            # [í•µì‹¬ 2] íƒ€ê²Ÿ(Y) ë°ì´í„° ì¸ì½”ë”© (ë¬¸ìì¼ ê²½ìš° ìˆ«ìë¡œ ë³€í™˜)
                            # íšŒê·€ì¸ë° Yê°€ ë¬¸ìë©´ ì—ëŸ¬, ë¶„ë¥˜ë©´ ìë™ ì¸ì½”ë”©
                            le_target = None
                            if st.session_state.task == "logit" and y.dtype == 'object':
                                le_target = LabelEncoder()
                                y = pd.Series(le_target.fit_transform(y), index=y.index)
                                st.info("â„¹ï¸ íƒ€ê²Ÿ ë³€ìˆ˜ê°€ ë¬¸ìì—´ì´ë¼ ìë™ìœ¼ë¡œ ìˆ«ìë¡œ ë³€í™˜(Encoding)ë˜ì—ˆìŠµë‹ˆë‹¤.")
                            
                            # X ë°ì´í„° ì „ì²˜ë¦¬ ì‹œì‘
                            num_cols = X.select_dtypes(include=['int64', 'float64']).columns.tolist()
                            cat_cols = X.select_dtypes(include=['object', 'category']).columns.tolist()
                            
                            # 1. ê°’ì´ ì—†ëŠ”(All-NaN) ìˆ˜ì¹˜í˜• ì»¬ëŸ¼ ì œì™¸
                            valid_num_cols = [c for c in num_cols if X[c].notna().sum() > 0]
                            num_cols = valid_num_cols 

                            # ë³€í™˜ê¸° ì¤€ë¹„
                            imputer = SimpleImputer(strategy='mean')
                            scaler = StandardScaler()
                            encoders = {}

                            # 2. ìˆ˜ì¹˜í˜• ì²˜ë¦¬
                            if num_cols:
                                # DataFrame í• ë‹¹ ì‹œ index=X.index í•„ìˆ˜
                                X_imputed = imputer.fit_transform(X[num_cols])
                                X_scaled = scaler.fit_transform(X_imputed)
                                X[num_cols] = pd.DataFrame(X_scaled, columns=num_cols, index=X.index)
                            
                            # 3. ë²”ì£¼í˜• ì²˜ë¦¬
                            for col in cat_cols:
                                X[col] = X[col].fillna("Unknown").astype(str)
                                le = LabelEncoder()
                                trans = le.fit_transform(X[col])
                                X[col] = pd.Series(trans, index=X.index)
                                encoders[col] = le
                            
                            # ìµœì¢… ì»¬ëŸ¼ ì •ë¦¬
                            final_features = num_cols + cat_cols
                            X = X[final_features]
                            
                            # æ–°å¢ï¼šæ£€æŸ¥å¹¶å¤„ç† X ä¸­çš„æ— ç©·å€¼
                            X = X.replace([np.inf, -np.inf], np.nan)
                            
                            # æ£€æŸ¥å‰©ä½™ NaN å¹¶æŠ¥å‘Š
                            nan_counts = X.isna().sum()
                            total_nans = nan_counts.sum()
                            if total_nans > 0:
                                st.info(f"â„¹ï¸ ì…ë ¥ ë³€ìˆ˜ì— {total_nans}ê°œì˜ ê²°ì¸¡ì¹˜ê°€ ë°œê²¬ë˜ì–´ ì²˜ë¦¬ë©ë‹ˆë‹¤.")
                            
                            # æœ€ç»ˆæ£€æŸ¥ï¼šç¡®ä¿æ²¡æœ‰ NaN æ®‹ç•™
                            if X.isna().sum().sum() > 0:
                                st.warning("âš ï¸ ì¼ë¶€ ê²°ì¸¡ì¹˜ ì²˜ë¦¬ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì¶”ê°€ ì •ì œê°€ í•„ìš”í•©ë‹ˆë‹¤.")
                            
                            #  ì „ì—­ ìƒíƒœ ì €ì¥
                            st.session_state.preprocess.update({
                                "feature_cols": final_features,
                                "imputer": imputer if num_cols else None,
                                "scaler": scaler if num_cols else None,
                                "encoders": encoders,
                                "num_cols": num_cols,
                                "cat_cols": cat_cols,
                                "target_encoder": le_target # Y ì¸ì½”ë”ë„ ì €ì¥
                            })
                            
                            # å¤„ç†ëœ ë°ì´í„° ì €ì¥
                            st.session_state.data["X_processed"] = X
                            st.session_state.data["y_processed"] = y
                            
                            st.success(f"âœ… ì „ì²˜ë¦¬ ì™„ë£Œ! (ë°ì´í„° ìˆ˜: {len(X)}í–‰)")
                            st.dataframe(X.head(), width='stretch')
                            
                        except Exception as e:
                            st.error(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                            
            with tab2:
                if "X_processed" in st.session_state.data and st.session_state.data["X_processed"] is not None:
                    if st.button("ğŸ” ë³€ìˆ˜ ì¤‘ìš”ë„ í™•ì¸"):
                        #  ì €ì¥ëœ ì²˜ë¦¬ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                        X_p = st.session_state.data["X_processed"]
                        y_p = st.session_state.data["y_processed"]
                        
                        # NaN ì²´í¬ (ë””ë²„ê¹…ìš©)
                        if X_p.isna().sum().sum() > 0 or y_p.isna().sum() > 0:
                            st.error("âŒ ë°ì´í„°ì— ì—¬ì „íˆ ê²°ì¸¡ì¹˜(NaN)ê°€ ë‚¨ì•„ìˆìŠµë‹ˆë‹¤. [ì „ì²˜ë¦¬ ì‹¤í–‰] ë²„íŠ¼ì„ ë‹¤ì‹œ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
                        else:
                            try:
                                # æ¨¡å‹ í”¼íŒ…
                                if st.session_state.task == "logit":
                                    model = DecisionTreeClassifier(max_depth=5, random_state=42)
                                else:
                                    model = DecisionTreeRegressor(max_depth=5, random_state=42)
                                
                                model.fit(X_p, y_p)
                                
                                imp = pd.DataFrame({
                                    "Feature": X_p.columns,
                                    "Importance": model.feature_importances_
                                }).sort_values("Importance", ascending=False)
                                
                                st.plotly_chart(
                                    px.bar(imp, x="Importance", y="Feature", orientation='h', title="ë³€ìˆ˜ ì¤‘ìš”ë„"),
                                    width='stretch'
                                )
                            except Exception as e:
                                st.error(f"ë¶„ì„ ì‹¤íŒ¨: {e}")
                                st.warning("íƒ€ê²Ÿ ë³€ìˆ˜(Y)ì˜ ë°ì´í„° íƒ€ì…ì„ í™•ì¸í•´ì£¼ì„¸ìš” (íšŒê·€ì¸ë° ë¬¸ìê°€ ë“¤ì–´ìˆëŠ”ì§€ ë“±).")
                else:
                    st.info("ğŸ‘ˆ ë¨¼ì € [ì „ì²˜ë¦¬ ì‹¤í–‰] ë²„íŠ¼ì„ ëˆŒëŸ¬ì£¼ì„¸ìš”.")
                    
# ----------------------
#  ë‹¨ê³„ 4ï¼šëª¨ë¸ í•™ìŠµ (ê°œì„ ëœ ë²„ì „)
# ----------------------
elif st.session_state.step == 4:
    st.subheader("ğŸš€ í•˜ì´ë¸Œë¦¬ë“œëª¨í˜• í•™ìŠµ")
    
    if "X_processed" not in st.session_state.data or st.session_state.data["X_processed"] is None:
        st.warning("âš ï¸ ë¨¼ì €ã€Œë°ì´í„° ì „ì²˜ë¦¬ã€ë‹¨ê³„ë¥¼ ì™„ë£Œí•˜ì„¸ìš”")
    else:
        X = st.session_state.data["X_processed"]
        y = st.session_state.data["y_processed"]
        
        st.markdown("### 1. í•™ìŠµ ì„¤ì • í™•ì¸")
        
        # [ìë™ ì§„ë‹¨] ì‘ì—… ìœ í˜•(Task)ê³¼ ë°ì´í„°(Target)ê°€ ë§ëŠ”ì§€ ê²€ì‚¬
        is_target_numeric = pd.api.types.is_numeric_dtype(y)
        target_unique_count = y.nunique()
        
        #  ì§„ë‹¨ 1: íƒ€ê²Ÿì´ 1ê°œë°–ì— ì—†ì„ ë•Œ (í•™ìŠµ ë¶ˆê°€)
        if target_unique_count < 2:
            st.error(f"âŒ íƒ€ê²Ÿ ë³€ìˆ˜(Y)ì˜ ê°’ ì¢…ë¥˜ê°€ 1ê°œ({y.unique()[0]})ë¿ì…ë‹ˆë‹¤. ëª¨ë¸ì„ í•™ìŠµí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            st.stop()
            
        #  ì§„ë‹¨ 2: ë¶„ë¥˜(Logit)ì¸ë° íƒ€ê²Ÿì´ ì—°ì†í˜• ìˆ«ìì¼ ë•Œ (ì„¤ì • ì‹¤ìˆ˜ ê°€ëŠ¥ì„± ë†’ìŒ)
        if st.session_state.task == "logit" and is_target_numeric and target_unique_count > 20:
            st.warning(f"âš ï¸ **ì£¼ì˜ ê°ì§€**: íƒ€ê²Ÿ ë³€ìˆ˜ê°€ 'ì—°ì†ëœ ìˆ«ì({target_unique_count}ê°œ ì¢…ë¥˜)'ë¡œ ë³´ì…ë‹ˆë‹¤.")
            st.info("ğŸ’¡ í˜¹ì‹œ **ë§¤ì¶œ, ê°€ê²©, ì ìˆ˜** ë“±ì„ ì˜ˆì¸¡í•˜ì‹œë‚˜ìš”? ê·¸ë ‡ë‹¤ë©´ ì™¼ìª½ ì‚¬ì´ë“œë°”ì˜ **[í•µì‹¬ ì„¤ì •]**ì—ì„œ **'ì˜ì‚¬ê²°ì •ë‚˜ë¬´(íšŒê·€)'**ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”.")

        col1, col2 = st.columns(2)
        with col1:
            test_size = st.slider("í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¹„ìœ¨ (Test Size)", 0.1, 0.4, 0.2, 0.05)
        with col2:
            st.info(f"í˜„ì¬ ë¶„ì„ ëª¨ë“œ: **{st.session_state.task}**")

        # -------------------------------------------------------
        # Stratify(ì¸µí™” ì¶”ì¶œ) ë¡œì§ ê°œì„ 
        # -------------------------------------------------------
        stratify_param = None
        
        if st.session_state.task == "logit":
            #  ê° í´ë˜ìŠ¤ë³„ ë°ì´í„°ê°€ ìµœì†Œ 2ê°œ ì´ìƒì´ì–´ì•¼ ì¸µí™” ì¶”ì¶œ ê°€ëŠ¥
            class_counts = y.value_counts()
            if (class_counts >= 2).all():
                stratify_param = y
                st.success(f"âœ… ì¸µí™” ì¶”ì¶œ(Stratified Split) ì ìš©ë¨ (í´ë˜ìŠ¤ ê· í˜• ìœ ì§€)")
            else:
                #  ì–´ë–¤ í´ë˜ìŠ¤ê°€ ë¬¸ì œì¸ì§€ ì•Œë ¤ì¤Œ
                problem_classes = class_counts[class_counts < 2].index.tolist()
                st.warning(f"âš ï¸ ì¸µí™” ì¶”ì¶œ ë¯¸ì ìš©: ë°ì´í„°ê°€ 1ê°œë¿ì¸ í´ë˜ìŠ¤ê°€ ìˆìŠµë‹ˆë‹¤. {problem_classes[:3]}...")
                st.caption("ë°ì´í„° ë¶€ì¡±ìœ¼ë¡œ ë¬´ì‘ìœ„ ë¶„í• (Random Split)ì„ ì§„í–‰í•©ë‹ˆë‹¤.")
        else:
            st.caption("â„¹ï¸ íšŒê·€ ë¶„ì„(Regression)ì€ ì¸µí™” ì¶”ì¶œì„ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        
        #  ë°ì´í„° ë¶„í• 
        try:
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=test_size, random_state=42, stratify=stratify_param
            )
        except ValueError as e:
            #  ì¸µí™” ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ (fallback)
            st.warning("âš ï¸ ì¸µí™” ì¶”ì¶œ ì‹¤íŒ¨ë¡œ ë‹¨ìˆœ ë¬´ì‘ìœ„ ë¶„í• ì„ ì‹œë„í•©ë‹ˆë‹¤.")
            X_train, X_test, y_train, y_test = train_test_split(
                X, y, test_size=test_size, random_state=42, stratify=None
            )

        st.divider()
        
        # [ìˆ˜ì •] ê°€ì¤‘ì¹˜ ì„¤ì • UI
        st.markdown("### 2. í•˜ì´ë¸Œë¦¬ë“œ ê°€ì¤‘ì¹˜ ì„¤ì •")
        w_col1, w_col2 = st.columns(2)
        with w_col1:
            reg_weight = st.slider("íšŒê·€ ëª¨ë¸(Linear/Logistic) ë¹„ì¤‘", 0.0, 1.0, 0.5)
        with w_col2:
            st.metric("íŠ¸ë¦¬ ëª¨ë¸(Tree) ë¹„ì¤‘", f"{1.0 - reg_weight:.1f}")
            
        #  ëª¨ë¸ ì •ì˜ ë° í•™ìŠµ
        if st.session_state.task == "logit":
            #  ë¡œì§€ìŠ¤í‹± íšŒê·€ (ìˆ˜ë ´ ê²½ê³  ë°©ì§€ë¥¼ ìœ„í•´ max_iter ì¦ê°€)
            reg_model = LogisticRegression(max_iter=2000) 
            dt_model = DecisionTreeClassifier(random_state=42, max_depth=10)
        else:
            reg_model = LinearRegression()
            dt_model = DecisionTreeRegressor(random_state=42, max_depth=10)
            
        if st.button("ğŸš€ ëª¨ë¸ í•™ìŠµ ì‹œì‘", type="primary"):
            with st.spinner("ëª¨ë¸ í•™ìŠµ ì¤‘ì…ë‹ˆë‹¤..."):
                try:
                    #  í•™ìŠµ ìˆ˜í–‰
                    reg_model.fit(X_train, y_train)
                    dt_model.fit(X_train, y_train)
                    
                    #  ëª¨ë¸ ë° ê²°ê³¼ ì €ì¥
                    st.session_state.models["regression"] = reg_model
                    st.session_state.models["decision_tree"] = dt_model
                    st.session_state.models["mixed_weights"] = {
                        "regression": reg_weight, "decision_tree": 1.0 - reg_weight
                    }
                    
                    st.session_state.data.update({
                        "X_train": X_train, "X_test": X_test, 
                        "y_train": y_train, "y_test": y_test
                    })
                    
                    st.success("âœ… ëª¨ë¸ í•™ìŠµì´ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
                    
                    #  ê²°ê³¼ ìš”ì•½
                    summ_col1, summ_col2 = st.columns(2)
                    with summ_col1:
                        st.markdown(f"**í•™ìŠµ ë°ì´í„°**: {len(X_train):,} ê±´")
                    with summ_col2:
                        st.markdown(f"**í…ŒìŠ¤íŠ¸ ë°ì´í„°**: {len(X_test):,} ê±´")
                        
                except Exception as e:
                    st.error(f"âŒ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
                    st.warning("ë°ì´í„°ì˜ íƒ€ê²Ÿ ë³€ìˆ˜(Y) íƒ€ì…ê³¼ 'ì‘ì—… ìœ í˜•(ë¶„ë¥˜/íšŒê·€)'ì´ ë§ëŠ”ì§€ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.")

# ----------------------
#  ë‹¨ê³„ 5ï¼šëª¨ë¸ ì˜ˆì¸¡
# ----------------------
elif st.session_state.step == 5:
    st.subheader("ğŸ¯ ëª¨ë¸ ì˜ˆì¸¡")
    
    if st.session_state.models["regression"] is None:
        st.warning("ë¨¼ì €ã€Œëª¨ë¸ í•™ìŠµã€ë‹¨ê³„ë¥¼ ì™„ë£Œí•˜ì„¸ìš”")
    else:
        def predict_pipeline(input_df):
            # 1. ì „ì²˜ë¦¬ ì ìš©
            preprocess = st.session_state.preprocess
            X = input_df.copy()
            
            num_cols = X.select_dtypes(include=["int64", "float64"]).columns
            cat_cols = X.select_dtypes(include=["object", "category"]).columns
            
            #  ìˆ˜ì¹˜í˜• ë³€í™˜
            if preprocess["imputer"]:
                X[num_cols] = preprocess["imputer"].transform(X[num_cols])
                X[num_cols] = preprocess["scaler"].transform(X[num_cols])
            
            #  ë²”ì£¼í˜• ë³€í™˜
            for col in cat_cols:
                X[col] = X[col].fillna("ì•Œ ìˆ˜ ì—†ìŒ").astype(str)
                encoder = preprocess["encoders"].get(col)
                if encoder:
                    if isinstance(encoder, LabelEncoder):
                        #  ë¯¸ì§€ì˜ ê°’ ì²˜ë¦¬
                        known_classes = set(encoder.classes_)
                        X[col] = X[col].apply(lambda x: x if x in known_classes else "ì•Œ ìˆ˜ ì—†ìŒ")
                        #  "ì•Œ ìˆ˜ ì—†ìŒ"ì´ í´ë˜ìŠ¤ì— ì—†ìœ¼ë©´ ì¶”ê°€ (ì„ì‹œ ì²˜ë¦¬)
                        if "ì•Œ ìˆ˜ ì—†ìŒ" not in known_classes:
                             #  LabelEncoderëŠ” ë™ì  ì¶”ê°€ê°€ ì–´ë ¤ìš°ë¯€ë¡œ 0ìœ¼ë¡œ ëŒ€ì²´í•˜ê±°ë‚˜ ì˜ˆì™¸ì²˜ë¦¬ í•„ìš”
                             #  ì—¬ê¸°ì„œëŠ” í¸ì˜ìƒ ê°€ì¥ ë¹ˆë„ ë†’ì€ ê°’ìœ¼ë¡œ ëŒ€ì²´ ê°€ì • ë˜ëŠ” 0
                             pass 
                        #  transform ì‹œ ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•´ try-except ê¶Œì¥
                        try:
                            X[col] = encoder.transform(X[col])
                        except:
                            X[col] = 0
                    else:
                        #  OneHotEncoder
                        ohe, ohe_cols = encoder
                        ohe_result = ohe.transform(X[[col]])
                        X = pd.concat([X.drop(col, axis=1), pd.DataFrame(ohe_result, columns=ohe_cols)], axis=1)
            
            #  ì»¬ëŸ¼ ìˆœì„œ ë§ì¶”ê¸°
            missing_cols = set(preprocess["feature_cols"]) - set(X.columns)
            for c in missing_cols:
                X[c] = 0
            X = X[preprocess["feature_cols"]]
            
            # 2. ì˜ˆì¸¡
            reg_model = st.session_state.models["regression"]
            dt_model = st.session_state.models["decision_tree"]
            weights = st.session_state.models["mixed_weights"]
            
            if st.session_state.task == "logit":
                reg_p = reg_model.predict_proba(X)[:, 1]
                dt_p = dt_model.predict_proba(X)[:, 1]
                mixed_p = weights["regression"] * reg_p + weights["decision_tree"] * dt_p
                pred = (mixed_p >= 0.5).astype(int)
                return pred, mixed_p
            else:
                reg_p = reg_model.predict(X)
                dt_p = dt_model.predict(X)
                mixed_p = weights["regression"] * reg_p + weights["decision_tree"] * dt_p
                return mixed_p, None

        mode = st.radio("ì˜ˆì¸¡ ë°©ì‹", ["ë‹¨ì¼ ë°ì´í„° ì…ë ¥", "ì¼ê´„ ì—…ë¡œë“œ (CSV)"])
        
        if mode == "ë‹¨ì¼ ë°ì´í„° ì…ë ¥":
            st.markdown("#### ë°ì´í„° ì…ë ¥")
            feature_cols = st.session_state.preprocess["feature_cols"]
            #  ì›ë³¸ ë°ì´í„°í”„ë ˆì„ êµ¬ì¡° ì°¸ì¡° (ì¸ì½”ë”© ì „)
            original_features = [c for c in st.session_state.data["merged"].columns 
                               if c not in [st.session_state.preprocess["target_col"]]]
            
            input_data = {}
            with st.form("pred_form"):
                cols = st.columns(3)
                for i, col in enumerate(original_features[:9]): #  ìµœëŒ€ 9ê°œë§Œ í‘œì‹œ
                    with cols[i % 3]:
                        #  ì›ë³¸ ë°ì´í„° íƒ€ì… í™•ì¸
                        col_type = st.session_state.data["merged"][col].dtype
                        if pd.api.types.is_numeric_dtype(col_type):
                            input_data[col] = st.number_input(col, value=0.0)
                        else:
                            opts = st.session_state.data["merged"][col].dropna().unique()
                            input_data[col] = st.selectbox(col, options=opts)
                submit = st.form_submit_button("ì˜ˆì¸¡í•˜ê¸°")
            
            if submit:
                input_df = pd.DataFrame([input_data])
                pred, proba = predict_pipeline(input_df)
                st.divider()
                if st.session_state.task == "logit":
                    st.metric("ì˜ˆì¸¡ ê²°ê³¼", "ì–‘ì„±(Positive)" if pred[0]==1 else "ìŒì„±(Negative)")
                    st.metric("í™•ë¥ ", f"{proba[0]:.2%}")
                else:
                    st.metric("ì˜ˆì¸¡ ê°’", f"{pred[0]:.4f}")
                    
        else:
            up_file = st.file_uploader("CSV ì—…ë¡œë“œ", type=["csv"])
            if up_file:
                batch_df = pd.read_csv(up_file)
                if st.button("ì¼ê´„ ì˜ˆì¸¡ ì‹œì‘"):
                    pred, proba = predict_pipeline(batch_df)
                    batch_df["Predicted"] = pred
                    if proba is not None:
                        batch_df["Probability"] = proba
                    st.dataframe(batch_df.head())
                    st.download_button("ê²°ê³¼ ë‹¤ìš´ë¡œë“œ", batch_df.to_csv().encode('utf-8'), "prediction.csv")

# ----------------------
#  ë‹¨ê³„ 6ï¼šì„±ëŠ¥ í‰ê°€
# ----------------------
elif st.session_state.step == 6:
    st.subheader("ğŸ“ˆ ëª¨ë¸ ì„±ëŠ¥ í‰ê°€")
    
    if st.session_state.models["regression"] is None:
        st.warning("ë¨¼ì €ã€Œëª¨ë¸ í•™ìŠµã€ë‹¨ê³„ë¥¼ ì™„ë£Œí•˜ì„¸ìš”")
    else:
        X_test = st.session_state.data["X_test"]
        y_test = st.session_state.data["y_test"]
        
        reg_model = st.session_state.models["regression"]
        dt_model = st.session_state.models["decision_tree"]
        weights = st.session_state.models["mixed_weights"]
        
        if st.session_state.task == "logit":
            #  í™•ë¥  ê³„ì‚°
            reg_p = reg_model.predict_proba(X_test)[:, 1]
            dt_p = dt_model.predict_proba(X_test)[:, 1]
            mixed_p = weights["regression"] * reg_p + weights["decision_tree"] * dt_p
            
            #  ì˜ˆì¸¡ê°’
            reg_pred = reg_model.predict(X_test)
            dt_pred = dt_model.predict(X_test)
            mixed_pred = (mixed_p >= 0.5).astype(int)
            
            #  í‰ê°€ í•¨ìˆ˜
            def get_metrics(y, pred, proba):
                return {
                    "ACC": accuracy_score(y, pred),
                    "AUC": auc(*roc_curve(y, proba)[:2])
                }
            
            m1 = get_metrics(y_test, reg_pred, reg_p)
            m2 = get_metrics(y_test, dt_pred, dt_p)
            m3 = get_metrics(y_test, mixed_pred, mixed_p)
            
            metrics = pd.DataFrame([m1, m2, m3], index=["íšŒê·€ë¶„ì„", "ì˜ì‚¬ê²°ì •ë‚˜ë¬´", "í•˜ì´ë¸Œë¦¬ë“œ"])
            st.table(metrics)
            
            #  ROC ê³¡ì„ 
            fpr, tpr, _ = roc_curve(y_test, mixed_p)
            fig = px.area(x=fpr, y=tpr, title=f"ROC Curve (Hybrid AUC={m3['AUC']:.3f})", 
                        labels=dict(x="False Positive Rate", y="True Positive Rate"))
            fig.add_shape(type='line', line=dict(dash='dash'), x0=0, x1=1, y0=0, y1=1)
            st.plotly_chart(fig, width='stretch')
            
        else:
            #  íšŒê·€ í‰ê°€
            reg_pred = reg_model.predict(X_test)
            dt_pred = dt_model.predict(X_test)
            mixed_pred = weights["regression"] * reg_pred + weights["decision_tree"] * dt_pred
            
            def get_reg_metrics(y, pred):
                return {
                    "MAE": mean_absolute_error(y, pred),
                    "RMSE": np.sqrt(mean_squared_error(y, pred)),
                    "R2": r2_score(y, pred)
                }
            
            m1 = get_reg_metrics(y_test, reg_pred)
            m2 = get_reg_metrics(y_test, dt_pred)
            m3 = get_reg_metrics(y_test, mixed_pred)
            
            metrics = pd.DataFrame([m1, m2, m3], index=["ì„ í˜•íšŒê·€", "ì˜ì‚¬ê²°ì •ë‚˜ë¬´", "í•˜ì´ë¸Œë¦¬ë“œ"])
            st.table(metrics)
            
            #  ì˜ˆì¸¡ vs ì‹¤ì œ
            fig = px.scatter(x=y_test, y=mixed_pred, title="ì‹¤ì œê°’ vs ì˜ˆì¸¡ê°’ (Hybrid)", 
                           labels={"x": "ì‹¤ì œê°’", "y": "ì˜ˆì¸¡ê°’"})
            fig.add_shape(type='line', line=dict(dash='dash', color='red'), 
                        x0=y_test.min(), x1=y_test.max(), y0=y_test.min(), y1=y_test.max())
            st.plotly_chart(fig, width='stretch')
            
        #  ì¤‘ìš”ë„ (Tree ê¸°ì¤€)
        if hasattr(dt_model, "feature_importances_"):
            st.markdown("### ğŸŒ³ ë³€ìˆ˜ ì¤‘ìš”ë„ (ì˜ì‚¬ê²°ì •ë‚˜ë¬´ ê¸°ì¤€)")
            imp_df = pd.DataFrame({
                "Feature": st.session_state.preprocess["feature_cols"],
                "Importance": dt_model.feature_importances_
            }).sort_values("Importance", ascending=False).head(10)
            
            fig_imp = px.bar(imp_df, x="Importance", y="Feature", orientation='h', title="Top 10 Feature Importance")
            st.plotly_chart(fig_imp, width='stretch')
